Directory structure:
└── danijar-dreamer/
    ├── README.md
    ├── dreamer.py
    ├── LICENSE
    ├── models.py
    ├── plotting.py
    ├── tools.py
    ├── wrappers.py
    ├── scores/
    │   ├── baselines.json
    │   └── dreamer.json
    └── .github/
        └── ISSUE_TEMPLATE/
            └── issue.md

================================================
FILE: README.md
================================================
# Dream to Control

**NOTE:** Check out the code for [DreamerV2](https://github.com/danijar/dreamerv2), which supports both Atari and DMControl environments.

Fast and simple implementation of the Dreamer agent in TensorFlow 2.

<img width="100%" src="https://imgur.com/x4NUHXl.gif">

If you find this code useful, please reference in your paper:

```
@article{hafner2019dreamer,
  title={Dream to Control: Learning Behaviors by Latent Imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}
```

## Method

![Dreamer](https://imgur.com/JrXC4rh.png)

Dreamer learns a world model that predicts ahead in a compact feature space.
From imagined feature sequences, it learns a policy and state-value function.
The value gradients are backpropagated through the multi-step predictions to
efficiently learn a long-horizon policy.

- [Project website][website]
- [Research paper][paper]
- [Official implementation][code] (TensorFlow 1)

[website]: https://danijar.com/dreamer
[paper]: https://arxiv.org/pdf/1912.01603.pdf
[code]: https://github.com/google-research/dreamer

## Instructions

Get dependencies:

```
pip3 install --user tensorflow-gpu==2.2.0
pip3 install --user tensorflow_probability
pip3 install --user git+git://github.com/deepmind/dm_control.git
pip3 install --user pandas
pip3 install --user matplotlib
```

Train the agent:

```
python3 dreamer.py --logdir ./logdir/dmc_walker_walk/dreamer/1 --task dmc_walker_walk
```

Generate plots:

```
python3 plotting.py --indir ./logdir --outdir ./plots --xaxis step --yaxis test/return --bins 3e4
```

Graphs and GIFs:

```
tensorboard --logdir ./logdir
```



================================================
FILE: dreamer.py
================================================
import argparse
import collections
import functools
import json
import os
import pathlib
import sys
import time

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['MUJOCO_GL'] = 'egl'

import numpy as np
import tensorflow as tf
from tensorflow.keras.mixed_precision import experimental as prec

tf.get_logger().setLevel('ERROR')

from tensorflow_probability import distributions as tfd

sys.path.append(str(pathlib.Path(__file__).parent))

import models
import tools
import wrappers


def define_config():
  config = tools.AttrDict()
  # General.
  config.logdir = pathlib.Path('.')
  config.seed = 0
  config.steps = 5e6
  config.eval_every = 1e4
  config.log_every = 1e3
  config.log_scalars = True
  config.log_images = True
  config.gpu_growth = True
  config.precision = 16
  # Environment.
  config.task = 'dmc_walker_walk'
  config.envs = 1
  config.parallel = 'none'
  config.action_repeat = 2
  config.time_limit = 1000
  config.prefill = 5000
  config.eval_noise = 0.0
  config.clip_rewards = 'none'
  # Model.
  config.deter_size = 200
  config.stoch_size = 30
  config.num_units = 400
  config.dense_act = 'elu'
  config.cnn_act = 'relu'
  config.cnn_depth = 32
  config.pcont = False
  config.free_nats = 3.0
  config.kl_scale = 1.0
  config.pcont_scale = 10.0
  config.weight_decay = 0.0
  config.weight_decay_pattern = r'.*'
  # Training.
  config.batch_size = 50
  config.batch_length = 50
  config.train_every = 1000
  config.train_steps = 100
  config.pretrain = 100
  config.model_lr = 6e-4
  config.value_lr = 8e-5
  config.actor_lr = 8e-5
  config.grad_clip = 100.0
  config.dataset_balance = False
  # Behavior.
  config.discount = 0.99
  config.disclam = 0.95
  config.horizon = 15
  config.action_dist = 'tanh_normal'
  config.action_init_std = 5.0
  config.expl = 'additive_gaussian'
  config.expl_amount = 0.3
  config.expl_decay = 0.0
  config.expl_min = 0.0
  return config


class Dreamer(tools.Module):

  def __init__(self, config, datadir, actspace, writer):
    self._c = config
    self._actspace = actspace
    self._actdim = actspace.n if hasattr(actspace, 'n') else actspace.shape[0]
    self._writer = writer
    self._random = np.random.RandomState(config.seed)
    with tf.device('cpu:0'):
      self._step = tf.Variable(count_steps(datadir, config), dtype=tf.int64)
    self._should_pretrain = tools.Once()
    self._should_train = tools.Every(config.train_every)
    self._should_log = tools.Every(config.log_every)
    self._last_log = None
    self._last_time = time.time()
    self._metrics = collections.defaultdict(tf.metrics.Mean)
    self._metrics['expl_amount']  # Create variable for checkpoint.
    self._float = prec.global_policy().compute_dtype
    self._strategy = tf.distribute.MirroredStrategy()
    with self._strategy.scope():
      self._dataset = iter(self._strategy.experimental_distribute_dataset(
          load_dataset(datadir, self._c)))
      self._build_model()

  def __call__(self, obs, reset, state=None, training=True):
    step = self._step.numpy().item()
    tf.summary.experimental.set_step(step)
    if state is not None and reset.any():
      mask = tf.cast(1 - reset, self._float)[:, None]
      state = tf.nest.map_structure(lambda x: x * mask, state)
    if self._should_train(step):
      log = self._should_log(step)
      n = self._c.pretrain if self._should_pretrain() else self._c.train_steps
      print(f'Training for {n} steps.')
      with self._strategy.scope():
        for train_step in range(n):
          log_images = self._c.log_images and log and train_step == 0
          self.train(next(self._dataset), log_images)
      if log:
        self._write_summaries()
    action, state = self.policy(obs, state, training)
    if training:
      self._step.assign_add(len(reset) * self._c.action_repeat)
    return action, state

  @tf.function
  def policy(self, obs, state, training):
    if state is None:
      latent = self._dynamics.initial(len(obs['image']))
      action = tf.zeros((len(obs['image']), self._actdim), self._float)
    else:
      latent, action = state
    embed = self._encode(preprocess(obs, self._c))
    latent, _ = self._dynamics.obs_step(latent, action, embed)
    feat = self._dynamics.get_feat(latent)
    if training:
      action = self._actor(feat).sample()
    else:
      action = self._actor(feat).mode()
    action = self._exploration(action, training)
    state = (latent, action)
    return action, state

  def load(self, filename):
    super().load(filename)
    self._should_pretrain()

  @tf.function()
  def train(self, data, log_images=False):
    self._strategy.experimental_run_v2(self._train, args=(data, log_images))

  def _train(self, data, log_images):
    with tf.GradientTape() as model_tape:
      embed = self._encode(data)
      post, prior = self._dynamics.observe(embed, data['action'])
      feat = self._dynamics.get_feat(post)
      image_pred = self._decode(feat)
      reward_pred = self._reward(feat)
      likes = tools.AttrDict()
      likes.image = tf.reduce_mean(image_pred.log_prob(data['image']))
      likes.reward = tf.reduce_mean(reward_pred.log_prob(data['reward']))
      if self._c.pcont:
        pcont_pred = self._pcont(feat)
        pcont_target = self._c.discount * data['discount']
        likes.pcont = tf.reduce_mean(pcont_pred.log_prob(pcont_target))
        likes.pcont *= self._c.pcont_scale
      prior_dist = self._dynamics.get_dist(prior)
      post_dist = self._dynamics.get_dist(post)
      div = tf.reduce_mean(tfd.kl_divergence(post_dist, prior_dist))
      div = tf.maximum(div, self._c.free_nats)
      model_loss = self._c.kl_scale * div - sum(likes.values())
      model_loss /= float(self._strategy.num_replicas_in_sync)

    with tf.GradientTape() as actor_tape:
      imag_feat = self._imagine_ahead(post)
      reward = self._reward(imag_feat).mode()
      if self._c.pcont:
        pcont = self._pcont(imag_feat).mean()
      else:
        pcont = self._c.discount * tf.ones_like(reward)
      value = self._value(imag_feat).mode()
      returns = tools.lambda_return(
          reward[:-1], value[:-1], pcont[:-1],
          bootstrap=value[-1], lambda_=self._c.disclam, axis=0)
      discount = tf.stop_gradient(tf.math.cumprod(tf.concat(
          [tf.ones_like(pcont[:1]), pcont[:-2]], 0), 0))
      actor_loss = -tf.reduce_mean(discount * returns)
      actor_loss /= float(self._strategy.num_replicas_in_sync)

    with tf.GradientTape() as value_tape:
      value_pred = self._value(imag_feat)[:-1]
      target = tf.stop_gradient(returns)
      value_loss = -tf.reduce_mean(discount * value_pred.log_prob(target))
      value_loss /= float(self._strategy.num_replicas_in_sync)

    model_norm = self._model_opt(model_tape, model_loss)
    actor_norm = self._actor_opt(actor_tape, actor_loss)
    value_norm = self._value_opt(value_tape, value_loss)

    if tf.distribute.get_replica_context().replica_id_in_sync_group == 0:
      if self._c.log_scalars:
        self._scalar_summaries(
            data, feat, prior_dist, post_dist, likes, div,
            model_loss, value_loss, actor_loss, model_norm, value_norm,
            actor_norm)
      if tf.equal(log_images, True):
        self._image_summaries(data, embed, image_pred)

  def _build_model(self):
    acts = dict(
        elu=tf.nn.elu, relu=tf.nn.relu, swish=tf.nn.swish,
        leaky_relu=tf.nn.leaky_relu)
    cnn_act = acts[self._c.cnn_act]
    act = acts[self._c.dense_act]
    self._encode = models.ConvEncoder(self._c.cnn_depth, cnn_act)
    self._dynamics = models.RSSM(
        self._c.stoch_size, self._c.deter_size, self._c.deter_size)
    self._decode = models.ConvDecoder(self._c.cnn_depth, cnn_act)
    self._reward = models.DenseDecoder((), 2, self._c.num_units, act=act)
    if self._c.pcont:
      self._pcont = models.DenseDecoder(
          (), 3, self._c.num_units, 'binary', act=act)
    self._value = models.DenseDecoder((), 3, self._c.num_units, act=act)
    self._actor = models.ActionDecoder(
        self._actdim, 4, self._c.num_units, self._c.action_dist,
        init_std=self._c.action_init_std, act=act)
    model_modules = [self._encode, self._dynamics, self._decode, self._reward]
    if self._c.pcont:
      model_modules.append(self._pcont)
    Optimizer = functools.partial(
        tools.Adam, wd=self._c.weight_decay, clip=self._c.grad_clip,
        wdpattern=self._c.weight_decay_pattern)
    self._model_opt = Optimizer('model', model_modules, self._c.model_lr)
    self._value_opt = Optimizer('value', [self._value], self._c.value_lr)
    self._actor_opt = Optimizer('actor', [self._actor], self._c.actor_lr)
    # Do a train step to initialize all variables, including optimizer
    # statistics. Ideally, we would use batch size zero, but that doesn't work
    # in multi-GPU mode.
    self.train(next(self._dataset))

  def _exploration(self, action, training):
    if training:
      amount = self._c.expl_amount
      if self._c.expl_decay:
        amount *= 0.5 ** (tf.cast(self._step, tf.float32) / self._c.expl_decay)
      if self._c.expl_min:
        amount = tf.maximum(self._c.expl_min, amount)
      self._metrics['expl_amount'].update_state(amount)
    elif self._c.eval_noise:
      amount = self._c.eval_noise
    else:
      return action
    if self._c.expl == 'additive_gaussian':
      return tf.clip_by_value(tfd.Normal(action, amount).sample(), -1, 1)
    if self._c.expl == 'completely_random':
      return tf.random.uniform(action.shape, -1, 1)
    if self._c.expl == 'epsilon_greedy':
      indices = tfd.Categorical(0 * action).sample()
      return tf.where(
          tf.random.uniform(action.shape[:1], 0, 1) < amount,
          tf.one_hot(indices, action.shape[-1], dtype=self._float),
          action)
    raise NotImplementedError(self._c.expl)

  def _imagine_ahead(self, post):
    if self._c.pcont:  # Last step could be terminal.
      post = {k: v[:, :-1] for k, v in post.items()}
    flatten = lambda x: tf.reshape(x, [-1] + list(x.shape[2:]))
    start = {k: flatten(v) for k, v in post.items()}
    policy = lambda state: self._actor(
        tf.stop_gradient(self._dynamics.get_feat(state))).sample()
    states = tools.static_scan(
        lambda prev, _: self._dynamics.img_step(prev, policy(prev)),
        tf.range(self._c.horizon), start)
    imag_feat = self._dynamics.get_feat(states)
    return imag_feat

  def _scalar_summaries(
      self, data, feat, prior_dist, post_dist, likes, div,
      model_loss, value_loss, actor_loss, model_norm, value_norm,
      actor_norm):
    self._metrics['model_grad_norm'].update_state(model_norm)
    self._metrics['value_grad_norm'].update_state(value_norm)
    self._metrics['actor_grad_norm'].update_state(actor_norm)
    self._metrics['prior_ent'].update_state(prior_dist.entropy())
    self._metrics['post_ent'].update_state(post_dist.entropy())
    for name, logprob in likes.items():
      self._metrics[name + '_loss'].update_state(-logprob)
    self._metrics['div'].update_state(div)
    self._metrics['model_loss'].update_state(model_loss)
    self._metrics['value_loss'].update_state(value_loss)
    self._metrics['actor_loss'].update_state(actor_loss)
    self._metrics['action_ent'].update_state(self._actor(feat).entropy())

  def _image_summaries(self, data, embed, image_pred):
    truth = data['image'][:6] + 0.5
    recon = image_pred.mode()[:6]
    init, _ = self._dynamics.observe(embed[:6, :5], data['action'][:6, :5])
    init = {k: v[:, -1] for k, v in init.items()}
    prior = self._dynamics.imagine(data['action'][:6, 5:], init)
    openl = self._decode(self._dynamics.get_feat(prior)).mode()
    model = tf.concat([recon[:, :5] + 0.5, openl + 0.5], 1)
    error = (model - truth + 1) / 2
    openl = tf.concat([truth, model, error], 2)
    tools.graph_summary(
        self._writer, tools.video_summary, 'agent/openl', openl)

  def _write_summaries(self):
    step = int(self._step.numpy())
    metrics = [(k, float(v.result())) for k, v in self._metrics.items()]
    if self._last_log is not None:
      duration = time.time() - self._last_time
      self._last_time += duration
      metrics.append(('fps', (step - self._last_log) / duration))
    self._last_log = step
    [m.reset_states() for m in self._metrics.values()]
    with (self._c.logdir / 'metrics.jsonl').open('a') as f:
      f.write(json.dumps({'step': step, **dict(metrics)}) + '\n')
    [tf.summary.scalar('agent/' + k, m) for k, m in metrics]
    print(f'[{step}]', ' / '.join(f'{k} {v:.1f}' for k, v in metrics))
    self._writer.flush()


def preprocess(obs, config):
  dtype = prec.global_policy().compute_dtype
  obs = obs.copy()
  with tf.device('cpu:0'):
    obs['image'] = tf.cast(obs['image'], dtype) / 255.0 - 0.5
    clip_rewards = dict(none=lambda x: x, tanh=tf.tanh)[config.clip_rewards]
    obs['reward'] = clip_rewards(obs['reward'])
  return obs


def count_steps(datadir, config):
  return tools.count_episodes(datadir)[1] * config.action_repeat


def load_dataset(directory, config):
  episode = next(tools.load_episodes(directory, 1))
  types = {k: v.dtype for k, v in episode.items()}
  shapes = {k: (None,) + v.shape[1:] for k, v in episode.items()}
  generator = lambda: tools.load_episodes(
      directory, config.train_steps, config.batch_length,
      config.dataset_balance)
  dataset = tf.data.Dataset.from_generator(generator, types, shapes)
  dataset = dataset.batch(config.batch_size, drop_remainder=True)
  dataset = dataset.map(functools.partial(preprocess, config=config))
  dataset = dataset.prefetch(10)
  return dataset


def summarize_episode(episode, config, datadir, writer, prefix):
  episodes, steps = tools.count_episodes(datadir)
  length = (len(episode['reward']) - 1) * config.action_repeat
  ret = episode['reward'].sum()
  print(f'{prefix.title()} episode of length {length} with return {ret:.1f}.')
  metrics = [
      (f'{prefix}/return', float(episode['reward'].sum())),
      (f'{prefix}/length', len(episode['reward']) - 1),
      (f'episodes', episodes)]
  step = count_steps(datadir, config)
  with (config.logdir / 'metrics.jsonl').open('a') as f:
    f.write(json.dumps(dict([('step', step)] + metrics)) + '\n')
  with writer.as_default():  # Env might run in a different thread.
    tf.summary.experimental.set_step(step)
    [tf.summary.scalar('sim/' + k, v) for k, v in metrics]
    if prefix == 'test':
      tools.video_summary(f'sim/{prefix}/video', episode['image'][None])


def make_env(config, writer, prefix, datadir, store):
  suite, task = config.task.split('_', 1)
  if suite == 'dmc':
    env = wrappers.DeepMindControl(task)
    env = wrappers.ActionRepeat(env, config.action_repeat)
    env = wrappers.NormalizeActions(env)
  elif suite == 'atari':
    env = wrappers.Atari(
        task, config.action_repeat, (64, 64), grayscale=False,
        life_done=True, sticky_actions=True)
    env = wrappers.OneHotAction(env)
  else:
    raise NotImplementedError(suite)
  env = wrappers.TimeLimit(env, config.time_limit / config.action_repeat)
  callbacks = []
  if store:
    callbacks.append(lambda ep: tools.save_episodes(datadir, [ep]))
  callbacks.append(
      lambda ep: summarize_episode(ep, config, datadir, writer, prefix))
  env = wrappers.Collect(env, callbacks, config.precision)
  env = wrappers.RewardObs(env)
  return env


def main(config):
  if config.gpu_growth:
    for gpu in tf.config.experimental.list_physical_devices('GPU'):
      tf.config.experimental.set_memory_growth(gpu, True)
  assert config.precision in (16, 32), config.precision
  if config.precision == 16:
    prec.set_policy(prec.Policy('mixed_float16'))
  config.steps = int(config.steps)
  config.logdir.mkdir(parents=True, exist_ok=True)
  print('Logdir', config.logdir)

  # Create environments.
  datadir = config.logdir / 'episodes'
  writer = tf.summary.create_file_writer(
      str(config.logdir), max_queue=1000, flush_millis=20000)
  writer.set_as_default()
  train_envs = [wrappers.Async(lambda: make_env(
      config, writer, 'train', datadir, store=True), config.parallel)
      for _ in range(config.envs)]
  test_envs = [wrappers.Async(lambda: make_env(
      config, writer, 'test', datadir, store=False), config.parallel)
      for _ in range(config.envs)]
  actspace = train_envs[0].action_space

  # Prefill dataset with random episodes.
  step = count_steps(datadir, config)
  prefill = max(0, config.prefill - step)
  print(f'Prefill dataset with {prefill} steps.')
  random_agent = lambda o, d, _: ([actspace.sample() for _ in d], None)
  tools.simulate(random_agent, train_envs, prefill / config.action_repeat)
  writer.flush()

  # Train and regularly evaluate the agent.
  step = count_steps(datadir, config)
  print(f'Simulating agent for {config.steps-step} steps.')
  agent = Dreamer(config, datadir, actspace, writer)
  if (config.logdir / 'variables.pkl').exists():
    print('Load checkpoint.')
    agent.load(config.logdir / 'variables.pkl')
  state = None
  while step < config.steps:
    print('Start evaluation.')
    tools.simulate(
        functools.partial(agent, training=False), test_envs, episodes=1)
    writer.flush()
    print('Start collection.')
    steps = config.eval_every // config.action_repeat
    state = tools.simulate(agent, train_envs, steps, state=state)
    step = count_steps(datadir, config)
    agent.save(config.logdir / 'variables.pkl')
  for env in train_envs + test_envs:
    env.close()


if __name__ == '__main__':
  try:
    import colored_traceback
    colored_traceback.add_hook()
  except ImportError:
    pass
  parser = argparse.ArgumentParser()
  for key, value in define_config().items():
    parser.add_argument(f'--{key}', type=tools.args_type(value), default=value)
  main(parser.parse_args())



================================================
FILE: LICENSE
================================================
Copyright (c) 2020 Danijar Hafner

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



================================================
FILE: models.py
================================================
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers as tfkl
from tensorflow_probability import distributions as tfd
from tensorflow.keras.mixed_precision import experimental as prec

import tools


class RSSM(tools.Module):

  def __init__(self, stoch=30, deter=200, hidden=200, act=tf.nn.elu):
    super().__init__()
    self._activation = act
    self._stoch_size = stoch
    self._deter_size = deter
    self._hidden_size = hidden
    self._cell = tfkl.GRUCell(self._deter_size)

  def initial(self, batch_size):
    dtype = prec.global_policy().compute_dtype
    return dict(
        mean=tf.zeros([batch_size, self._stoch_size], dtype),
        std=tf.zeros([batch_size, self._stoch_size], dtype),
        stoch=tf.zeros([batch_size, self._stoch_size], dtype),
        deter=self._cell.get_initial_state(None, batch_size, dtype))

  @tf.function
  def observe(self, embed, action, state=None):
    if state is None:
      state = self.initial(tf.shape(action)[0])
    embed = tf.transpose(embed, [1, 0, 2])
    action = tf.transpose(action, [1, 0, 2])
    post, prior = tools.static_scan(
        lambda prev, inputs: self.obs_step(prev[0], *inputs),
        (action, embed), (state, state))
    post = {k: tf.transpose(v, [1, 0, 2]) for k, v in post.items()}
    prior = {k: tf.transpose(v, [1, 0, 2]) for k, v in prior.items()}
    return post, prior

  @tf.function
  def imagine(self, action, state=None):
    if state is None:
      state = self.initial(tf.shape(action)[0])
    assert isinstance(state, dict), state
    action = tf.transpose(action, [1, 0, 2])
    prior = tools.static_scan(self.img_step, action, state)
    prior = {k: tf.transpose(v, [1, 0, 2]) for k, v in prior.items()}
    return prior

  def get_feat(self, state):
    return tf.concat([state['stoch'], state['deter']], -1)

  def get_dist(self, state):
    return tfd.MultivariateNormalDiag(state['mean'], state['std'])

  @tf.function
  def obs_step(self, prev_state, prev_action, embed):
    prior = self.img_step(prev_state, prev_action)
    x = tf.concat([prior['deter'], embed], -1)
    x = self.get('obs1', tfkl.Dense, self._hidden_size, self._activation)(x)
    x = self.get('obs2', tfkl.Dense, 2 * self._stoch_size, None)(x)
    mean, std = tf.split(x, 2, -1)
    std = tf.nn.softplus(std) + 0.1
    stoch = self.get_dist({'mean': mean, 'std': std}).sample()
    post = {'mean': mean, 'std': std, 'stoch': stoch, 'deter': prior['deter']}
    return post, prior

  @tf.function
  def img_step(self, prev_state, prev_action):
    x = tf.concat([prev_state['stoch'], prev_action], -1)
    x = self.get('img1', tfkl.Dense, self._hidden_size, self._activation)(x)
    x, deter = self._cell(x, [prev_state['deter']])
    deter = deter[0]  # Keras wraps the state in a list.
    x = self.get('img2', tfkl.Dense, self._hidden_size, self._activation)(x)
    x = self.get('img3', tfkl.Dense, 2 * self._stoch_size, None)(x)
    mean, std = tf.split(x, 2, -1)
    std = tf.nn.softplus(std) + 0.1
    stoch = self.get_dist({'mean': mean, 'std': std}).sample()
    prior = {'mean': mean, 'std': std, 'stoch': stoch, 'deter': deter}
    return prior


class ConvEncoder(tools.Module):

  def __init__(self, depth=32, act=tf.nn.relu):
    self._act = act
    self._depth = depth

  def __call__(self, obs):
    kwargs = dict(strides=2, activation=self._act)
    x = tf.reshape(obs['image'], (-1,) + tuple(obs['image'].shape[-3:]))
    x = self.get('h1', tfkl.Conv2D, 1 * self._depth, 4, **kwargs)(x)
    x = self.get('h2', tfkl.Conv2D, 2 * self._depth, 4, **kwargs)(x)
    x = self.get('h3', tfkl.Conv2D, 4 * self._depth, 4, **kwargs)(x)
    x = self.get('h4', tfkl.Conv2D, 8 * self._depth, 4, **kwargs)(x)
    shape = tf.concat([tf.shape(obs['image'])[:-3], [32 * self._depth]], 0)
    return tf.reshape(x, shape)


class ConvDecoder(tools.Module):

  def __init__(self, depth=32, act=tf.nn.relu, shape=(64, 64, 3)):
    self._act = act
    self._depth = depth
    self._shape = shape

  def __call__(self, features):
    kwargs = dict(strides=2, activation=self._act)
    x = self.get('h1', tfkl.Dense, 32 * self._depth, None)(features)
    x = tf.reshape(x, [-1, 1, 1, 32 * self._depth])
    x = self.get('h2', tfkl.Conv2DTranspose, 4 * self._depth, 5, **kwargs)(x)
    x = self.get('h3', tfkl.Conv2DTranspose, 2 * self._depth, 5, **kwargs)(x)
    x = self.get('h4', tfkl.Conv2DTranspose, 1 * self._depth, 6, **kwargs)(x)
    x = self.get('h5', tfkl.Conv2DTranspose, self._shape[-1], 6, strides=2)(x)
    mean = tf.reshape(x, tf.concat([tf.shape(features)[:-1], self._shape], 0))
    return tfd.Independent(tfd.Normal(mean, 1), len(self._shape))


class DenseDecoder(tools.Module):

  def __init__(self, shape, layers, units, dist='normal', act=tf.nn.elu):
    self._shape = shape
    self._layers = layers
    self._units = units
    self._dist = dist
    self._act = act

  def __call__(self, features):
    x = features
    for index in range(self._layers):
      x = self.get(f'h{index}', tfkl.Dense, self._units, self._act)(x)
    x = self.get(f'hout', tfkl.Dense, np.prod(self._shape))(x)
    x = tf.reshape(x, tf.concat([tf.shape(features)[:-1], self._shape], 0))
    if self._dist == 'normal':
      return tfd.Independent(tfd.Normal(x, 1), len(self._shape))
    if self._dist == 'binary':
      return tfd.Independent(tfd.Bernoulli(x), len(self._shape))
    raise NotImplementedError(self._dist)


class ActionDecoder(tools.Module):

  def __init__(
      self, size, layers, units, dist='tanh_normal', act=tf.nn.elu,
      min_std=1e-4, init_std=5, mean_scale=5):
    self._size = size
    self._layers = layers
    self._units = units
    self._dist = dist
    self._act = act
    self._min_std = min_std
    self._init_std = init_std
    self._mean_scale = mean_scale

  def __call__(self, features):
    raw_init_std = np.log(np.exp(self._init_std) - 1)
    x = features
    for index in range(self._layers):
      x = self.get(f'h{index}', tfkl.Dense, self._units, self._act)(x)
    if self._dist == 'tanh_normal':
      # https://www.desmos.com/calculator/rcmcf5jwe7
      x = self.get(f'hout', tfkl.Dense, 2 * self._size)(x)
      mean, std = tf.split(x, 2, -1)
      mean = self._mean_scale * tf.tanh(mean / self._mean_scale)
      std = tf.nn.softplus(std + raw_init_std) + self._min_std
      dist = tfd.Normal(mean, std)
      dist = tfd.TransformedDistribution(dist, tools.TanhBijector())
      dist = tfd.Independent(dist, 1)
      dist = tools.SampleDist(dist)
    elif self._dist == 'onehot':
      x = self.get(f'hout', tfkl.Dense, self._size)(x)
      dist = tools.OneHotDist(x)
    else:
      raise NotImplementedError(dist)
    return dist



================================================
FILE: plotting.py
================================================
import argparse
import collections
import functools
import json
import multiprocessing as mp
import pathlib
import re
import subprocess

import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import numpy as np
import pandas as pd

# import matplotlib
# matplotlib.rcParams['mathtext.fontset'] = 'stix'
# matplotlib.rcParams['font.family'] = 'STIXGeneral'

Run = collections.namedtuple('Run', 'task method seed xs ys color')

PALETTE = 10 * (
    '#377eb8', '#4daf4a', '#984ea3', '#e41a1c', '#ff7f00', '#a65628',
    '#f781bf', '#888888', '#a6cee3', '#b2df8a', '#cab2d6', '#fb9a99',
    '#fdbf6f')

LEGEND = dict(
    fontsize='medium', numpoints=1, labelspacing=0, columnspacing=1.2,
    handlelength=1.5, handletextpad=0.5, ncol=4, loc='lower center')


def find_keys(args):
  filename = next(args.indir[0].glob('**/*.jsonl'))
  keys = set()
  for line in filename.read_text().split('\n'):
    if line:
      keys |= json.loads(line).keys()
  print(f'Keys ({len(keys)}):', ', '.join(keys), flush=True)


def load_runs(args):
  toload = []
  for indir in args.indir:
    filenames = list(indir.glob('**/*.jsonl'))
    for filename in filenames:
      task, method, seed = filename.relative_to(indir).parts[:-1]
      if not any(p.search(task) for p in args.tasks):
        continue
      if not any(p.search(method) for p in args.methods):
        continue
      if method not in args.colors:
        args.colors[method] = args.palette[len(args.colors)]
      toload.append((filename, indir))
  print(f'Loading {len(toload)} of {len(filenames)} runs...')
  jobs = [functools.partial(load_run, f, i, args) for f, i in toload]
  with mp.Pool(10) as pool:
    promises = [pool.apply_async(j) for j in jobs]
    runs = [p.get() for p in promises]
  runs = [r for r in runs if r is not None]
  return runs


def load_run(filename, indir, args):
  task, method, seed = filename.relative_to(indir).parts[:-1]
  try:
    # Future pandas releases will support JSON files with NaN values.
    # df = pd.read_json(filename, lines=True)
    with filename.open() as f:
      df = pd.DataFrame([json.loads(l) for l in f.readlines()])
  except ValueError as e:
    print('Invalid', filename.relative_to(indir), e)
    return
  try:
    df = df[[args.xaxis, args.yaxis]].dropna()
  except KeyError:
    return
  xs = df[args.xaxis].to_numpy()
  ys = df[args.yaxis].to_numpy()
  color = args.colors[method]
  return Run(task, method, seed, xs, ys, color)


def load_baselines(args):
  runs = []
  directory = pathlib.Path(__file__).parent / 'baselines'
  for filename in directory.glob('**/*.json'):
    for task, methods in json.loads(filename.read_text()).items():
      for method, score in methods.items():
        if not any(p.search(method) for p in args.baselines):
          continue
        if method not in args.colors:
          args.colors[method] = args.palette[len(args.colors)]
        color = args.colors[method]
        runs.append(Run(task, method, None, None, score, color))
  return runs


def stats(runs):
  baselines = sorted(set(r.method for r in runs if r.xs is None))
  runs = [r for r in runs if r.xs is not None]
  tasks = sorted(set(r.task for r in runs))
  methods = sorted(set(r.method for r in runs))
  seeds = sorted(set(r.seed for r in runs))
  print('Loaded', len(runs), 'runs.')
  print(f'Tasks     ({len(tasks)}):', ', '.join(tasks))
  print(f'Methods   ({len(methods)}):', ', '.join(methods))
  print(f'Seeds     ({len(seeds)}):', ', '.join(seeds))
  print(f'Baselines ({len(baselines)}):', ', '.join(baselines))


def figure(runs, args):
  tasks = sorted(set(r.task for r in runs if r.xs is not None))
  rows = int(np.ceil(len(tasks) / args.cols))
  figsize = args.size[0] * args.cols, args.size[1] * rows
  fig, axes = plt.subplots(rows, args.cols, figsize=figsize)
  for task, ax in zip(tasks, axes.flatten()):
    relevant = [r for r in runs if r.task == task]
    plot(task, ax, relevant, args)
  if args.xlim:
    for ax in axes[:-1].flatten():
      ax.xaxis.get_offset_text().set_visible(False)
  if args.xlabel:
    for ax in axes[-1]:
      ax.set_xlabel(args.xlabel)
  if args.ylabel:
    for ax in axes[:, 0]:
      ax.set_ylabel(args.ylabel)
  for ax in axes[len(tasks):]:
    ax.axis('off')
  legend(fig, args.labels, **LEGEND)
  return fig


def plot(task, ax, runs, args):
  try:
    title = task.split('_', 1)[1].replace('_', ' ').title()
  except IndexError:
    title = task.title()
  ax.set_title(title)
  methods = []
  methods += sorted(set(r.method for r in runs if r.xs is not None))
  methods += sorted(set(r.method for r in runs if r.xs is None))
  xlim = [+np.inf, -np.inf]
  for index, method in enumerate(methods):
    relevant = [r for r in runs if r.method == method]
    if not relevant:
      continue
    if any(r.xs is None for r in relevant):
      baseline(index, method, ax, relevant, args)
    else:
      if args.aggregate == 'std':
        xs, ys = curve_std(index, method, ax, relevant, args)
      elif args.aggregate == 'none':
        xs, ys = curve_individual(index, method, ax, relevant, args)
      else:
        raise NotImplementedError(args.aggregate)
      xlim = [min(xlim[0], xs.min()), max(xlim[1], xs.max())]
  ax.ticklabel_format(axis='x', style='sci', scilimits=(0, 0))
  steps = [1, 2, 2.5, 5, 10]
  ax.xaxis.set_major_locator(ticker.MaxNLocator(args.xticks, steps=steps))
  ax.yaxis.set_major_locator(ticker.MaxNLocator(args.yticks, steps=steps))
  ax.set_xlim(args.xlim or xlim)
  if args.xlim:
    ticks = sorted({*ax.get_xticks(), *args.xlim})
    ticks = [x for x in ticks if args.xlim[0] <= x <= args.xlim[1]]
    ax.set_xticks(ticks)
  if args.ylim:
    ax.set_ylim(args.ylim)
    ticks = sorted({*ax.get_yticks(), *args.ylim})
    ticks = [x for x in ticks if args.ylim[0] <= x <= args.ylim[1]]
    ax.set_yticks(ticks)


def curve_individual(index, method, ax, runs, args):
  if args.bins:
    for index, run in enumerate(runs):
      xs, ys = binning(run.xs, run.ys, args.bins, np.nanmean)
      runs[index] = run._replace(xs=xs, ys=ys)
  zorder = 10000 - 10 * index - 1
  for run in runs:
    ax.plot(run.xs, run.ys, label=method, color=run.color, zorder=zorder)
  return runs[0].xs, runs[0].ys


def curve_std(index, method, ax, runs, args):
  if args.bins:
    for index, run in enumerate(runs):
      xs, ys = binning(run.xs, run.ys, args.bins, np.nanmean)
      runs[index] = run._replace(xs=xs, ys=ys)
  xs = np.concatenate([r.xs for r in runs])
  ys = np.concatenate([r.ys for r in runs])
  order = np.argsort(xs)
  xs, ys = xs[order], ys[order]
  color = runs[0].color
  if args.bins:
    reducer = lambda y: (np.nanmean(np.array(y)), np.nanstd(np.array(y)))
    xs, ys = binning(xs, ys, args.bins, reducer)
    ys, std = ys.T
    kw = dict(color=color, zorder=10000 - 10 * index, alpha=0.1, linewidths=0)
    ax.fill_between(xs, ys - std, ys + std, **kw)
  ax.plot(xs, ys, label=method, color=color, zorder=10000 - 10 * index - 1)
  return xs, ys


def baseline(index, method, ax, runs, args):
  assert len(runs) == 1 and runs[0].xs is None
  y = np.mean(runs[0].ys)
  kw = dict(ls='--', color=runs[0].color, zorder=5000 - 10 * index - 1)
  ax.axhline(y, label=method, **kw)


def binning(xs, ys, bins, reducer):
  binned_xs = np.arange(xs.min(), xs.max() + 1e-10, bins)
  binned_ys = []
  for start, stop in zip([-np.inf] + list(binned_xs), binned_xs):
    left = (xs <= start).sum()
    right = (xs <= stop).sum()
    binned_ys.append(reducer(ys[left:right]))
  binned_ys = np.array(binned_ys)
  return binned_xs, binned_ys


def legend(fig, mapping=None, **kwargs):
  entries = {}
  for ax in fig.axes:
    for handle, label in zip(*ax.get_legend_handles_labels()):
      if mapping and label in mapping:
        label = mapping[label]
      entries[label] = handle
  leg = fig.legend(entries.values(), entries.keys(), **kwargs)
  leg.get_frame().set_edgecolor('white')
  extent = leg.get_window_extent(fig.canvas.get_renderer())
  extent = extent.transformed(fig.transFigure.inverted())
  yloc, xloc = kwargs['loc'].split()
  y0 = dict(lower=extent.y1, center=0, upper=0)[yloc]
  y1 = dict(lower=1, center=1, upper=extent.y0)[yloc]
  x0 = dict(left=extent.x1, center=0, right=0)[xloc]
  x1 = dict(left=1, center=1, right=extent.x0)[xloc]
  fig.tight_layout(rect=[x0, y0, x1, y1], h_pad=0.5, w_pad=0.5)


def save(fig, args):
  args.outdir.mkdir(parents=True, exist_ok=True)
  filename = args.outdir / 'curves.png'
  fig.savefig(filename, dpi=130)
  print('Saved to', filename)
  filename = args.outdir / 'curves.pdf'
  fig.savefig(filename)
  try:
    subprocess.call(['pdfcrop', str(filename), str(filename)])
  except FileNotFoundError:
    pass  # Install texlive-extra-utils.


def main(args):
  find_keys(args)
  runs = load_runs(args) + load_baselines(args)
  stats(runs)
  if not runs:
    print('Noting to plot.')
    return
  print('Plotting...')
  fig = figure(runs, args)
  save(fig, args)


def parse_args():
  boolean = lambda x: bool(['False', 'True'].index(x))
  parser = argparse.ArgumentParser()
  parser.add_argument('--indir', nargs='+', type=pathlib.Path, required=True)
  parser.add_argument('--outdir', type=pathlib.Path, required=True)
  parser.add_argument('--subdir', type=boolean, default=True)
  parser.add_argument('--xaxis', type=str, required=True)
  parser.add_argument('--yaxis', type=str, required=True)
  parser.add_argument('--tasks', nargs='+', default=[r'.*'])
  parser.add_argument('--methods', nargs='+', default=[r'.*'])
  parser.add_argument('--baselines', nargs='+', default=[])
  parser.add_argument('--bins', type=float, default=0)
  parser.add_argument('--aggregate', type=str, default='std')
  parser.add_argument('--size', nargs=2, type=float, default=[2.5, 2.3])
  parser.add_argument('--cols', type=int, default=4)
  parser.add_argument('--xlim', nargs=2, type=float, default=None)
  parser.add_argument('--ylim', nargs=2, type=float, default=None)
  parser.add_argument('--xlabel', type=str, default=None)
  parser.add_argument('--ylabel', type=str, default=None)
  parser.add_argument('--xticks', type=int, default=6)
  parser.add_argument('--yticks', type=int, default=5)
  parser.add_argument('--labels', nargs='+', default=None)
  parser.add_argument('--palette', nargs='+', default=PALETTE)
  parser.add_argument('--colors', nargs='+', default={})
  args = parser.parse_args()
  if args.subdir:
    args.outdir /= args.indir[0].stem
  args.indir = [d.expanduser() for d in args.indir]
  args.outdir = args.outdir.expanduser()
  if args.labels:
    assert len(args.labels) % 2 == 0
    args.labels = {k: v for k, v in zip(args.labels[:-1], args.labels[1:])}
  if args.colors:
    assert len(args.colors) % 2 == 0
    args.colors = {k: v for k, v in zip(args.colors[:-1], args.colors[1:])}
  args.tasks = [re.compile(p) for p in args.tasks]
  args.methods = [re.compile(p) for p in args.methods]
  args.baselines = [re.compile(p) for p in args.baselines]
  args.palette = 10 * args.palette
  return args


if __name__ == '__main__':
  main(parse_args())



================================================
FILE: tools.py
================================================
import datetime
import io
import pathlib
import pickle
import re
import uuid

import gym
import numpy as np
import tensorflow as tf
import tensorflow.compat.v1 as tf1
import tensorflow_probability as tfp
from tensorflow.keras.mixed_precision import experimental as prec
from tensorflow_probability import distributions as tfd


class AttrDict(dict):

  __setattr__ = dict.__setitem__
  __getattr__ = dict.__getitem__


class Module(tf.Module):

  def save(self, filename):
    values = tf.nest.map_structure(lambda x: x.numpy(), self.variables)
    with pathlib.Path(filename).open('wb') as f:
      pickle.dump(values, f)

  def load(self, filename):
    with pathlib.Path(filename).open('rb') as f:
      values = pickle.load(f)
    tf.nest.map_structure(lambda x, y: x.assign(y), self.variables, values)

  def get(self, name, ctor, *args, **kwargs):
    # Create or get layer by name to avoid mentioning it in the constructor.
    if not hasattr(self, '_modules'):
      self._modules = {}
    if name not in self._modules:
      self._modules[name] = ctor(*args, **kwargs)
    return self._modules[name]


def nest_summary(structure):
  if isinstance(structure, dict):
    return {k: nest_summary(v) for k, v in structure.items()}
  if isinstance(structure, list):
    return [nest_summary(v) for v in structure]
  if hasattr(structure, 'shape'):
    return str(structure.shape).replace(', ', 'x').strip('(), ')
  return '?'


def graph_summary(writer, fn, *args):
  step = tf.summary.experimental.get_step()
  def inner(*args):
    tf.summary.experimental.set_step(step)
    with writer.as_default():
      fn(*args)
  return tf.numpy_function(inner, args, [])


def video_summary(name, video, step=None, fps=20):
  name = name if isinstance(name, str) else name.decode('utf-8')
  if np.issubdtype(video.dtype, np.floating):
    video = np.clip(255 * video, 0, 255).astype(np.uint8)
  B, T, H, W, C = video.shape
  try:
    frames = video.transpose((1, 2, 0, 3, 4)).reshape((T, H, B * W, C))
    summary = tf1.Summary()
    image = tf1.Summary.Image(height=B * H, width=T * W, colorspace=C)
    image.encoded_image_string = encode_gif(frames, fps)
    summary.value.add(tag=name + '/gif', image=image)
    tf.summary.experimental.write_raw_pb(summary.SerializeToString(), step)
  except (IOError, OSError) as e:
    print('GIF summaries require ffmpeg in $PATH.', e)
    frames = video.transpose((0, 2, 1, 3, 4)).reshape((1, B * H, T * W, C))
    tf.summary.image(name + '/grid', frames, step)


def encode_gif(frames, fps):
  from subprocess import Popen, PIPE
  h, w, c = frames[0].shape
  pxfmt = {1: 'gray', 3: 'rgb24'}[c]
  cmd = ' '.join([
      f'ffmpeg -y -f rawvideo -vcodec rawvideo',
      f'-r {fps:.02f} -s {w}x{h} -pix_fmt {pxfmt} -i - -filter_complex',
      f'[0:v]split[x][z];[z]palettegen[y];[x]fifo[x];[x][y]paletteuse',
      f'-r {fps:.02f} -f gif -'])
  proc = Popen(cmd.split(' '), stdin=PIPE, stdout=PIPE, stderr=PIPE)
  for image in frames:
    proc.stdin.write(image.tostring())
  out, err = proc.communicate()
  if proc.returncode:
    raise IOError('\n'.join([' '.join(cmd), err.decode('utf8')]))
  del proc
  return out


def simulate(agent, envs, steps=0, episodes=0, state=None):
  # Initialize or unpack simulation state.
  if state is None:
    step, episode = 0, 0
    done = np.ones(len(envs), np.bool)
    length = np.zeros(len(envs), np.int32)
    obs = [None] * len(envs)
    agent_state = None
  else:
    step, episode, done, length, obs, agent_state = state
  while (steps and step < steps) or (episodes and episode < episodes):
    # Reset envs if necessary.
    if done.any():
      indices = [index for index, d in enumerate(done) if d]
      promises = [envs[i].reset(blocking=False) for i in indices]
      for index, promise in zip(indices, promises):
        obs[index] = promise()
    # Step agents.
    obs = {k: np.stack([o[k] for o in obs]) for k in obs[0]}
    action, agent_state = agent(obs, done, agent_state)
    action = np.array(action)
    assert len(action) == len(envs)
    # Step envs.
    promises = [e.step(a, blocking=False) for e, a in zip(envs, action)]
    obs, _, done = zip(*[p()[:3] for p in promises])
    obs = list(obs)
    done = np.stack(done)
    episode += int(done.sum())
    length += 1
    step += (done * length).sum()
    length *= (1 - done)
  # Return new state to allow resuming the simulation.
  return (step - steps, episode - episodes, done, length, obs, agent_state)


def count_episodes(directory):
  filenames = directory.glob('*.npz')
  lengths = [int(n.stem.rsplit('-', 1)[-1]) - 1 for n in filenames]
  episodes, steps = len(lengths), sum(lengths)
  return episodes, steps


def save_episodes(directory, episodes):
  directory = pathlib.Path(directory).expanduser()
  directory.mkdir(parents=True, exist_ok=True)
  timestamp = datetime.datetime.now().strftime('%Y%m%dT%H%M%S')
  for episode in episodes:
    identifier = str(uuid.uuid4().hex)
    length = len(episode['reward'])
    filename = directory / f'{timestamp}-{identifier}-{length}.npz'
    with io.BytesIO() as f1:
      np.savez_compressed(f1, **episode)
      f1.seek(0)
      with filename.open('wb') as f2:
        f2.write(f1.read())


def load_episodes(directory, rescan, length=None, balance=False, seed=0):
  directory = pathlib.Path(directory).expanduser()
  random = np.random.RandomState(seed)
  cache = {}
  while True:
    for filename in directory.glob('*.npz'):
      if filename not in cache:
        try:
          with filename.open('rb') as f:
            episode = np.load(f)
            episode = {k: episode[k] for k in episode.keys()}
        except Exception as e:
          print(f'Could not load episode: {e}')
          continue
        cache[filename] = episode
    keys = list(cache.keys())
    for index in random.choice(len(keys), rescan):
      episode = cache[keys[index]]
      if length:
        total = len(next(iter(episode.values())))
        available = total - length
        if available < 1:
          print(f'Skipped short episode of length {available}.')
          continue
        if balance:
          index = min(random.randint(0, total), available)
        else:
          index = int(random.randint(0, available))
        episode = {k: v[index: index + length] for k, v in episode.items()}
      yield episode


class DummyEnv:

  def __init__(self):
    self._random = np.random.RandomState(seed=0)
    self._step = None

  @property
  def observation_space(self):
    low = np.zeros([64, 64, 3], dtype=np.uint8)
    high = 255 * np.ones([64, 64, 3], dtype=np.uint8)
    spaces = {'image': gym.spaces.Box(low, high)}
    return gym.spaces.Dict(spaces)

  @property
  def action_space(self):
    low = -np.ones([5], dtype=np.float32)
    high = np.ones([5], dtype=np.float32)
    return gym.spaces.Box(low, high)

  def reset(self):
    self._step = 0
    obs = self.observation_space.sample()
    return obs

  def step(self, action):
    obs = self.observation_space.sample()
    reward = self._random.uniform(0, 1)
    self._step += 1
    done = self._step >= 1000
    info = {}
    return obs, reward, done, info


class SampleDist:

  def __init__(self, dist, samples=100):
    self._dist = dist
    self._samples = samples

  @property
  def name(self):
    return 'SampleDist'

  def __getattr__(self, name):
    return getattr(self._dist, name)

  def mean(self):
    samples = self._dist.sample(self._samples)
    return tf.reduce_mean(samples, 0)

  def mode(self):
    sample = self._dist.sample(self._samples)
    logprob = self._dist.log_prob(sample)
    return tf.gather(sample, tf.argmax(logprob))[0]

  def entropy(self):
    sample = self._dist.sample(self._samples)
    logprob = self.log_prob(sample)
    return -tf.reduce_mean(logprob, 0)


class OneHotDist:

  def __init__(self, logits=None, probs=None):
    self._dist = tfd.Categorical(logits=logits, probs=probs)
    self._num_classes = self.mean().shape[-1]
    self._dtype = prec.global_policy().compute_dtype

  @property
  def name(self):
    return 'OneHotDist'

  def __getattr__(self, name):
    return getattr(self._dist, name)

  def prob(self, events):
    indices = tf.argmax(events, axis=-1)
    return self._dist.prob(indices)

  def log_prob(self, events):
    indices = tf.argmax(events, axis=-1)
    return self._dist.log_prob(indices)

  def mean(self):
    return self._dist.probs_parameter()

  def mode(self):
    return self._one_hot(self._dist.mode())

  def sample(self, amount=None):
    amount = [amount] if amount else []
    indices = self._dist.sample(*amount)
    sample = self._one_hot(indices)
    probs = self._dist.probs_parameter()
    sample += tf.cast(probs - tf.stop_gradient(probs), self._dtype)
    return sample

  def _one_hot(self, indices):
    return tf.one_hot(indices, self._num_classes, dtype=self._dtype)


class TanhBijector(tfp.bijectors.Bijector):

  def __init__(self, validate_args=False, name='tanh'):
    super().__init__(
        forward_min_event_ndims=0,
        validate_args=validate_args,
        name=name)

  def _forward(self, x):
    return tf.nn.tanh(x)

  def _inverse(self, y):
    dtype = y.dtype
    y = tf.cast(y, tf.float32)
    y = tf.where(
        tf.less_equal(tf.abs(y), 1.),
        tf.clip_by_value(y, -0.99999997, 0.99999997), y)
    y = tf.atanh(y)
    y = tf.cast(y, dtype)
    return y

  def _forward_log_det_jacobian(self, x):
    log2 = tf.math.log(tf.constant(2.0, dtype=x.dtype))
    return 2.0 * (log2 - x - tf.nn.softplus(-2.0 * x))


def lambda_return(
    reward, value, pcont, bootstrap, lambda_, axis):
  # Setting lambda=1 gives a discounted Monte Carlo return.
  # Setting lambda=0 gives a fixed 1-step return.
  assert reward.shape.ndims == value.shape.ndims, (reward.shape, value.shape)
  if isinstance(pcont, (int, float)):
    pcont = pcont * tf.ones_like(reward)
  dims = list(range(reward.shape.ndims))
  dims = [axis] + dims[1:axis] + [0] + dims[axis + 1:]
  if axis != 0:
    reward = tf.transpose(reward, dims)
    value = tf.transpose(value, dims)
    pcont = tf.transpose(pcont, dims)
  if bootstrap is None:
    bootstrap = tf.zeros_like(value[-1])
  next_values = tf.concat([value[1:], bootstrap[None]], 0)
  inputs = reward + pcont * next_values * (1 - lambda_)
  returns = static_scan(
      lambda agg, cur: cur[0] + cur[1] * lambda_ * agg,
      (inputs, pcont), bootstrap, reverse=True)
  if axis != 0:
    returns = tf.transpose(returns, dims)
  return returns


class Adam(tf.Module):

  def __init__(self, name, modules, lr, clip=None, wd=None, wdpattern=r'.*'):
    self._name = name
    self._modules = modules
    self._clip = clip
    self._wd = wd
    self._wdpattern = wdpattern
    self._opt = tf.optimizers.Adam(lr)
    self._opt = prec.LossScaleOptimizer(self._opt, 'dynamic')
    self._variables = None

  @property
  def variables(self):
    return self._opt.variables()

  def __call__(self, tape, loss):
    if self._variables is None:
      variables = [module.variables for module in self._modules]
      self._variables = tf.nest.flatten(variables)
      count = sum(np.prod(x.shape) for x in self._variables)
      print(f'Found {count} {self._name} parameters.')
    assert len(loss.shape) == 0, loss.shape
    with tape:
      loss = self._opt.get_scaled_loss(loss)
    grads = tape.gradient(loss, self._variables)
    grads = self._opt.get_unscaled_gradients(grads)
    norm = tf.linalg.global_norm(grads)
    if self._clip:
      grads, _ = tf.clip_by_global_norm(grads, self._clip, norm)
    if self._wd:
      context = tf.distribute.get_replica_context()
      context.merge_call(self._apply_weight_decay)
    self._opt.apply_gradients(zip(grads, self._variables))
    return norm

  def _apply_weight_decay(self, strategy):
    print('Applied weight decay to variables:')
    for var in self._variables:
      if re.search(self._wdpattern, self._name + '/' + var.name):
        print('- ' + self._name + '/' + var.name)
        strategy.extended.update(var, lambda var: self._wd * var)


def args_type(default):
  if isinstance(default, bool):
    return lambda x: bool(['False', 'True'].index(x))
  if isinstance(default, int):
    return lambda x: float(x) if ('e' in x or '.' in x) else int(x)
  if isinstance(default, pathlib.Path):
    return lambda x: pathlib.Path(x).expanduser()
  return type(default)


def static_scan(fn, inputs, start, reverse=False):
  last = start
  outputs = [[] for _ in tf.nest.flatten(start)]
  indices = range(len(tf.nest.flatten(inputs)[0]))
  if reverse:
    indices = reversed(indices)
  for index in indices:
    inp = tf.nest.map_structure(lambda x: x[index], inputs)
    last = fn(last, inp)
    [o.append(l) for o, l in zip(outputs, tf.nest.flatten(last))]
  if reverse:
    outputs = [list(reversed(x)) for x in outputs]
  outputs = [tf.stack(x, 0) for x in outputs]
  return tf.nest.pack_sequence_as(start, outputs)


def _mnd_sample(self, sample_shape=(), seed=None, name='sample'):
  return tf.random.normal(
      tuple(sample_shape) + tuple(self.event_shape),
      self.mean(), self.stddev(), self.dtype, seed, name)


tfd.MultivariateNormalDiag.sample = _mnd_sample


def _cat_sample(self, sample_shape=(), seed=None, name='sample'):
  assert len(sample_shape) in (0, 1), sample_shape
  assert len(self.logits_parameter().shape) == 2
  indices = tf.random.categorical(
      self.logits_parameter(), sample_shape[0] if sample_shape else 1,
      self.dtype, seed, name)
  if not sample_shape:
    indices = indices[..., 0]
  return indices


tfd.Categorical.sample = _cat_sample


class Every:

  def __init__(self, every):
    self._every = every
    self._last = None

  def __call__(self, step):
    if self._last is None:
      self._last = step
      return True
    if step >= self._last + self._every:
      self._last += self._every
      return True
    return False


class Once:

  def __init__(self):
    self._once = True

  def __call__(self):
    if self._once:
      self._once = False
      return True
    return False



================================================
FILE: wrappers.py
================================================
import atexit
import functools
import sys
import threading
import traceback

import gym
import numpy as np
from PIL import Image


class DeepMindControl:

  def __init__(self, name, size=(64, 64), camera=None):
    domain, task = name.split('_', 1)
    if domain == 'cup':  # Only domain with multiple words.
      domain = 'ball_in_cup'
    if isinstance(domain, str):
      from dm_control import suite
      self._env = suite.load(domain, task)
    else:
      assert task is None
      self._env = domain()
    self._size = size
    if camera is None:
      camera = dict(quadruped=2).get(domain, 0)
    self._camera = camera

  @property
  def observation_space(self):
    spaces = {}
    for key, value in self._env.observation_spec().items():
      spaces[key] = gym.spaces.Box(
          -np.inf, np.inf, value.shape, dtype=np.float32)
    spaces['image'] = gym.spaces.Box(
        0, 255, self._size + (3,), dtype=np.uint8)
    return gym.spaces.Dict(spaces)

  @property
  def action_space(self):
    spec = self._env.action_spec()
    return gym.spaces.Box(spec.minimum, spec.maximum, dtype=np.float32)

  def step(self, action):
    time_step = self._env.step(action)
    obs = dict(time_step.observation)
    obs['image'] = self.render()
    reward = time_step.reward or 0
    done = time_step.last()
    info = {'discount': np.array(time_step.discount, np.float32)}
    return obs, reward, done, info

  def reset(self):
    time_step = self._env.reset()
    obs = dict(time_step.observation)
    obs['image'] = self.render()
    return obs

  def render(self, *args, **kwargs):
    if kwargs.get('mode', 'rgb_array') != 'rgb_array':
      raise ValueError("Only render mode 'rgb_array' is supported.")
    return self._env.physics.render(*self._size, camera_id=self._camera)


class Atari:

  LOCK = threading.Lock()

  def __init__(
      self, name, action_repeat=4, size=(84, 84), grayscale=True, noops=30,
      life_done=False, sticky_actions=True):
    import gym
    version = 0 if sticky_actions else 4
    name = ''.join(word.title() for word in name.split('_'))
    with self.LOCK:
      self._env = gym.make('{}NoFrameskip-v{}'.format(name, version))
    self._action_repeat = action_repeat
    self._size = size
    self._grayscale = grayscale
    self._noops = noops
    self._life_done = life_done
    self._lives = None
    shape = self._env.observation_space.shape[:2] + (() if grayscale else (3,))
    self._buffers = [np.empty(shape, dtype=np.uint8) for _ in range(2)]
    self._random = np.random.RandomState(seed=None)

  @property
  def observation_space(self):
    shape = self._size + (1 if self._grayscale else 3,)
    space = gym.spaces.Box(low=0, high=255, shape=shape, dtype=np.uint8)
    return gym.spaces.Dict({'image': space})

  @property
  def action_space(self):
    return self._env.action_space

  def close(self):
    return self._env.close()

  def reset(self):
    with self.LOCK:
      self._env.reset()
    noops = self._random.randint(1, self._noops + 1)
    for _ in range(noops):
      done = self._env.step(0)[2]
      if done:
        with self.LOCK:
          self._env.reset()
    self._lives = self._env.ale.lives()
    if self._grayscale:
      self._env.ale.getScreenGrayscale(self._buffers[0])
    else:
      self._env.ale.getScreenRGB2(self._buffers[0])
    self._buffers[1].fill(0)
    return self._get_obs()

  def step(self, action):
    total_reward = 0.0
    for step in range(self._action_repeat):
      _, reward, done, info = self._env.step(action)
      total_reward += reward
      if self._life_done:
        lives = self._env.ale.lives()
        done = done or lives < self._lives
        self._lives = lives
      if done:
        break
      elif step >= self._action_repeat - 2:
        index = step - (self._action_repeat - 2)
        if self._grayscale:
          self._env.ale.getScreenGrayscale(self._buffers[index])
        else:
          self._env.ale.getScreenRGB2(self._buffers[index])
    obs = self._get_obs()
    return obs, total_reward, done, info

  def render(self, mode):
    return self._env.render(mode)

  def _get_obs(self):
    if self._action_repeat > 1:
      np.maximum(self._buffers[0], self._buffers[1], out=self._buffers[0])
    image = np.array(Image.fromarray(self._buffers[0]).resize(
        self._size, Image.BILINEAR))
    image = np.clip(image, 0, 255).astype(np.uint8)
    image = image[:, :, None] if self._grayscale else image
    return {'image': image}


class Collect:

  def __init__(self, env, callbacks=None, precision=32):
    self._env = env
    self._callbacks = callbacks or ()
    self._precision = precision
    self._episode = None

  def __getattr__(self, name):
    return getattr(self._env, name)

  def step(self, action):
    obs, reward, done, info = self._env.step(action)
    obs = {k: self._convert(v) for k, v in obs.items()}
    transition = obs.copy()
    transition['action'] = action
    transition['reward'] = reward
    transition['discount'] = info.get('discount', np.array(1 - float(done)))
    self._episode.append(transition)
    if done:
      episode = {k: [t[k] for t in self._episode] for k in self._episode[0]}
      episode = {k: self._convert(v) for k, v in episode.items()}
      info['episode'] = episode
      for callback in self._callbacks:
        callback(episode)
    return obs, reward, done, info

  def reset(self):
    obs = self._env.reset()
    transition = obs.copy()
    transition['action'] = np.zeros(self._env.action_space.shape)
    transition['reward'] = 0.0
    transition['discount'] = 1.0
    self._episode = [transition]
    return obs

  def _convert(self, value):
    value = np.array(value)
    if np.issubdtype(value.dtype, np.floating):
      dtype = {16: np.float16, 32: np.float32, 64: np.float64}[self._precision]
    elif np.issubdtype(value.dtype, np.signedinteger):
      dtype = {16: np.int16, 32: np.int32, 64: np.int64}[self._precision]
    elif np.issubdtype(value.dtype, np.uint8):
      dtype = np.uint8
    else:
      raise NotImplementedError(value.dtype)
    return value.astype(dtype)


class TimeLimit:

  def __init__(self, env, duration):
    self._env = env
    self._duration = duration
    self._step = None

  def __getattr__(self, name):
    return getattr(self._env, name)

  def step(self, action):
    assert self._step is not None, 'Must reset environment.'
    obs, reward, done, info = self._env.step(action)
    self._step += 1
    if self._step >= self._duration:
      done = True
      if 'discount' not in info:
        info['discount'] = np.array(1.0).astype(np.float32)
      self._step = None
    return obs, reward, done, info

  def reset(self):
    self._step = 0
    return self._env.reset()


class ActionRepeat:

  def __init__(self, env, amount):
    self._env = env
    self._amount = amount

  def __getattr__(self, name):
    return getattr(self._env, name)

  def step(self, action):
    done = False
    total_reward = 0
    current_step = 0
    while current_step < self._amount and not done:
      obs, reward, done, info = self._env.step(action)
      total_reward += reward
      current_step += 1
    return obs, total_reward, done, info


class NormalizeActions:

  def __init__(self, env):
    self._env = env
    self._mask = np.logical_and(
        np.isfinite(env.action_space.low),
        np.isfinite(env.action_space.high))
    self._low = np.where(self._mask, env.action_space.low, -1)
    self._high = np.where(self._mask, env.action_space.high, 1)

  def __getattr__(self, name):
    return getattr(self._env, name)

  @property
  def action_space(self):
    low = np.where(self._mask, -np.ones_like(self._low), self._low)
    high = np.where(self._mask, np.ones_like(self._low), self._high)
    return gym.spaces.Box(low, high, dtype=np.float32)

  def step(self, action):
    original = (action + 1) / 2 * (self._high - self._low) + self._low
    original = np.where(self._mask, original, action)
    return self._env.step(original)


class ObsDict:

  def __init__(self, env, key='obs'):
    self._env = env
    self._key = key

  def __getattr__(self, name):
    return getattr(self._env, name)

  @property
  def observation_space(self):
    spaces = {self._key: self._env.observation_space}
    return gym.spaces.Dict(spaces)

  @property
  def action_space(self):
    return self._env.action_space

  def step(self, action):
    obs, reward, done, info = self._env.step(action)
    obs = {self._key: np.array(obs)}
    return obs, reward, done, info

  def reset(self):
    obs = self._env.reset()
    obs = {self._key: np.array(obs)}
    return obs


class OneHotAction:

  def __init__(self, env):
    assert isinstance(env.action_space, gym.spaces.Discrete)
    self._env = env

  def __getattr__(self, name):
    return getattr(self._env, name)

  @property
  def action_space(self):
    shape = (self._env.action_space.n,)
    space = gym.spaces.Box(low=0, high=1, shape=shape, dtype=np.float32)
    space.sample = self._sample_action
    return space

  def step(self, action):
    index = np.argmax(action).astype(int)
    reference = np.zeros_like(action)
    reference[index] = 1
    if not np.allclose(reference, action):
      raise ValueError(f'Invalid one-hot action:\n{action}')
    return self._env.step(index)

  def reset(self):
    return self._env.reset()

  def _sample_action(self):
    actions = self._env.action_space.n
    index = self._random.randint(0, actions)
    reference = np.zeros(actions, dtype=np.float32)
    reference[index] = 1.0
    return reference


class RewardObs:

  def __init__(self, env):
    self._env = env

  def __getattr__(self, name):
    return getattr(self._env, name)

  @property
  def observation_space(self):
    spaces = self._env.observation_space.spaces
    assert 'reward' not in spaces
    spaces['reward'] = gym.spaces.Box(-np.inf, np.inf, dtype=np.float32)
    return gym.spaces.Dict(spaces)

  def step(self, action):
    obs, reward, done, info = self._env.step(action)
    obs['reward'] = reward
    return obs, reward, done, info

  def reset(self):
    obs = self._env.reset()
    obs['reward'] = 0.0
    return obs


class Async:

  _ACCESS = 1
  _CALL = 2
  _RESULT = 3
  _EXCEPTION = 4
  _CLOSE = 5

  def __init__(self, ctor, strategy='process'):
    self._strategy = strategy
    if strategy == 'none':
      self._env = ctor()
    elif strategy == 'thread':
      import multiprocessing.dummy as mp
    elif strategy == 'process':
      import multiprocessing as mp
    else:
      raise NotImplementedError(strategy)
    if strategy != 'none':
      self._conn, conn = mp.Pipe()
      self._process = mp.Process(target=self._worker, args=(ctor, conn))
      atexit.register(self.close)
      self._process.start()
    self._obs_space = None
    self._action_space = None

  @property
  def observation_space(self):
    if not self._obs_space:
      self._obs_space = self.__getattr__('observation_space')
    return self._obs_space

  @property
  def action_space(self):
    if not self._action_space:
      self._action_space = self.__getattr__('action_space')
    return self._action_space

  def __getattr__(self, name):
    if self._strategy == 'none':
      return getattr(self._env, name)
    self._conn.send((self._ACCESS, name))
    return self._receive()

  def call(self, name, *args, **kwargs):
    blocking = kwargs.pop('blocking', True)
    if self._strategy == 'none':
      return functools.partial(getattr(self._env, name), *args, **kwargs)
    payload = name, args, kwargs
    self._conn.send((self._CALL, payload))
    promise = self._receive
    return promise() if blocking else promise

  def close(self):
    if self._strategy == 'none':
      try:
        self._env.close()
      except AttributeError:
        pass
      return
    try:
      self._conn.send((self._CLOSE, None))
      self._conn.close()
    except IOError:
      # The connection was already closed.
      pass
    self._process.join()

  def step(self, action, blocking=True):
    return self.call('step', action, blocking=blocking)

  def reset(self, blocking=True):
    return self.call('reset', blocking=blocking)

  def _receive(self):
    try:
      message, payload = self._conn.recv()
    except ConnectionResetError:
      raise RuntimeError('Environment worker crashed.')
    # Re-raise exceptions in the main process.
    if message == self._EXCEPTION:
      stacktrace = payload
      raise Exception(stacktrace)
    if message == self._RESULT:
      return payload
    raise KeyError(f'Received message of unexpected type {message}')

  def _worker(self, ctor, conn):
    try:
      env = ctor()
      while True:
        try:
          # Only block for short times to have keyboard exceptions be raised.
          if not conn.poll(0.1):
            continue
          message, payload = conn.recv()
        except (EOFError, KeyboardInterrupt):
          break
        if message == self._ACCESS:
          name = payload
          result = getattr(env, name)
          conn.send((self._RESULT, result))
          continue
        if message == self._CALL:
          name, args, kwargs = payload
          result = getattr(env, name)(*args, **kwargs)
          conn.send((self._RESULT, result))
          continue
        if message == self._CLOSE:
          assert payload is None
          break
        raise KeyError(f'Received message of unknown type {message}')
    except Exception:
      stacktrace = ''.join(traceback.format_exception(*sys.exc_info()))
      print(f'Error in environment process: {stacktrace}')
      conn.send((self._EXCEPTION, stacktrace))
    conn.close()



================================================
FILE: scores/baselines.json
================================================
{"dmc_acrobot_swingup": {"d4pg_100m": 91.7, "a3c_100m_proprio": 41.9}, "dmc_cartpole_balance": {"d4pg_100m": 992.8, "a3c_100m_proprio": 951.6}, "dmc_cartpole_swingup": {"d4pg_100m": 862.0, "planet_1e6": 821, "a3c_100m_proprio": 558.4}, "dmc_cartpole_balance_sparse": {"d4pg_100m": 1000.0, "a3c_100m_proprio": 857.4}, "dmc_cartpole_swingup_sparse": {"d4pg_100m": 482.0, "a3c_100m_proprio": 179.8}, "dmc_cheetah_run": {"slac_3e6": 880, "d4pg_100m": 523.8, "planet_1e6": 662, "a3c_100m_proprio": 213.9}, "dmc_cup_catch": {"slac_3e6": 970, "d4pg_100m": 980.5, "planet_1e6": 930, "a3c_100m_proprio": 104.7}, "dmc_finger_spin": {"slac_3e6": 950, "d4pg_100m": 985.7, "planet_1e6": 700, "a3c_100m_proprio": 129.4}, "dmc_finger_turn_easy": {"d4pg_100m": 971.4, "a3c_100m_proprio": 167.3}, "dmc_finger_turn_hard": {"d4pg_100m": 966.0, "a3c_100m_proprio": 88.7}, "dmc_hopper_hop": {"d4pg_100m": 242.0, "a3c_100m_proprio": 0.5}, "dmc_hopper_stand": {"d4pg_100m": 929.9, "a3c_100m_proprio": 27.9}, "dmc_reacher_easy": {"d4pg_100m": 967.4, "planet_1e6": 832, "a3c_100m_proprio": 95.6}, "dmc_reacher_hard": {"d4pg_100m": 957.1, "a3c_100m_proprio": 39.7}, "dmc_walker_stand": {"d4pg_100m": 985.2, "a3c_100m_proprio": 378.4}, "dmc_walker_walk": {"slac_3e6": 840, "d4pg_100m": 968.3, "planet_1e6": 951, "a3c_100m_proprio": 311.0}, "dmc_walker_run": {"d4pg_100m": 567.2, "a3c_100m_proprio": 191.8}, "dmc_pendulum_swingup": {"d4pg_100m": 680.9, "a3c_100m_proprio": 48.6}}


================================================
FILE: scores/dreamer.json
================================================
[{"task": "dmc_cartpole_swingup", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [75.9375, 145.378125, 482.8, 712.7, 846.1, 855.85, 866.15, 850.3, 868.0, 859.25, 856.55, 817.95, 841.4, 833.2, 858.75, 841.6, 871.5, 858.85, 869.55, 854.0, 865.05, 874.05, 866.7, 878.05, 859.55, 862.45, 875.55, 876.4, 877.85, 871.65, 868.55, 840.4, 831.7, 857.25, 847.1, 866.65, 863.35, 865.65, 859.8, 872.2, 875.35, 867.1, 869.15, 875.0, 843.95, 875.9, 866.45, 872.25, 858.7, 865.6]}, {"task": "dmc_cartpole_swingup", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [73.1875, 276.153125, 654.825, 849.85, 871.7, 863.85, 866.55, 858.25, 863.75, 862.15, 870.45, 770.35, 860.3, 860.7, 874.25, 872.55, 873.3, 856.05, 839.2, 871.6, 823.125, 871.85, 868.25, 867.15, 839.15, 839.75, 834.4, 848.5, 858.55, 843.15, 872.45, 871.1, 837.1, 872.0, 861.4, 863.8, 877.25, 875.5, 873.7, 807.525, 874.8, 873.4, 878.05, 879.15, 854.2, 873.7, 841.85, 858.9, 858.5, 863.75]}, {"task": "dmc_cartpole_swingup", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [76.0625, 125.9390625, 412.35, 685.15, 828.8, 851.5, 852.5, 844.3, 853.15, 852.9, 848.15, 832.65, 830.25, 846.65, 808.4, 849.95, 844.55, 859.15, 872.0, 866.2, 871.9, 811.6, 867.7, 870.45, 864.7, 857.8, 872.05, 877.1, 877.4, 873.9, 878.25, 876.8181818181819, 875.55, 877.75, 873.5, 862.15, 876.0, 880.15, 879.35, 880.1, 877.55, 872.4, 808.95, 877.5, 876.25, 875.75, 874.5, 872.0, 875.0, 871.8]}, {"task": "dmc_cartpole_swingup", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [74.625, 75.00625, 87.4640625, 185.225, 394.55, 573.7, 718.3, 790.9, 814.75, 838.1, 840.05, 803.2, 846.05, 826.85, 844.5, 859.1, 864.5, 850.15, 865.35, 858.95, 854.85, 845.5, 868.85, 830.25, 815.6, 792.375, 848.0, 859.25, 788.025, 790.9, 805.0, 797.05, 806.65, 784.45, 849.15, 868.65, 808.8, 869.95, 850.55, 867.75, 857.3, 868.7, 837.85, 873.5, 856.9, 868.75, 850.85, 835.2, 794.475, 869.9]}, {"task": "dmc_cartpole_swingup", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [73.4375, 74.3625, 74.575, 98.84375, 142.25, 247.2625, 529.7, 681.05, 767.3, 844.25, 861.5, 859.9, 862.35, 871.15, 866.65, 855.85, 873.15, 864.15, 864.1, 872.5, 871.4, 876.55, 861.3, 877.85, 851.15, 744.2, 836.7, 871.2, 870.8, 859.05, 843.7, 867.15, 852.05, 826.3, 760.925, 873.75, 862.85, 763.55, 855.65, 822.4, 864.6, 848.05, 866.8, 865.7, 869.0, 870.35, 851.2, 877.1, 867.5, 872.55]}, {"task": "dmc_quadruped_walk", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [29.65625, 61.43125, 75.18125, 108.6015625, 154.3375, 207.721875, 245.66875, 291.49375, 328.15, 374.05, 589.0, 597.8, 570.45, 608.0625, 607.0, 724.1, 664.65, 785.1, 793.2, 827.4, 804.7, 843.2, 777.65, 850.35, 844.625, 820.1, 901.15, 891.0, 914.95, 916.35, 898.4, 915.6, 912.55, 915.7, 910.55, 831.05, 936.55, 914.75, 916.05, 948.6, 953.95, 927.8, 890.05, 920.45, 919.05, 890.6, 935.15, 892.8, 920.55, 941.7]}, {"task": "dmc_quadruped_walk", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [15.8203125, 49.215625, 92.1296875, 66.915625, 107.5390625, 152.64375, 196.8875, 229.775, 258.4875, 320.55, 348.9875, 470.475, 400.85, 406.8375, 502.1125, 506.6625, 527.4, 552.6, 631.15, 697.625, 712.45, 679.25, 787.55, 836.15, 893.3, 869.45, 881.95, 876.65, 838.9, 897.25, 901.9, 864.4, 890.45, 870.85, 931.2, 903.5, 929.75, 897.45, 904.5, 840.2, 907.5, 936.65, 913.35, 925.7, 904.65, 944.5, 929.05, 918.05, 920.05, 921.9]}, {"task": "dmc_quadruped_walk", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [1.6181640625, 40.0, 89.7296875, 117.621875, 246.06875, 332.8625, 273.4375, 326.5875, 382.7, 346.8625, 434.525, 493.25, 468.775, 533.4, 640.95, 638.35, 737.75, 740.95, 856.6, 880.55, 904.75, 851.2, 861.7, 901.9, 893.3, 931.7, 928.85, 933.0, 953.1, 883.7, 908.8, 895.7, 929.95, 937.8, 932.45, 953.25, 912.9, 944.15, 952.4, 948.55, 950.5, 928.1, 935.8, 956.05, 940.8, 955.9, 965.9, 961.55, 941.6, 915.9]}, {"task": "dmc_quadruped_walk", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [8.671875, 57.34609375, 45.7125, 118.9453125, 117.5, 147.08125, 301.2125, 234.6375, 327.0625, 347.225, 441.525, 458.1, 436.85, 418.4125, 468.425, 595.45, 691.35, 781.85, 826.95, 841.0, 820.5, 853.75, 821.65, 876.05, 877.8, 884.65, 867.95, 885.3, 908.7, 901.35, 924.25, 947.2, 950.6, 936.0, 929.2, 941.35, 933.6, 957.55, 949.5, 907.5, 885.45, 920.05, 930.3, 864.6, 904.45, 928.65, 950.1, 829.2125, 884.05, 910.35]}, {"task": "dmc_quadruped_walk", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [33.6875, 87.2765625, 73.2640625, 140.58125, 200.525, 273.525, 332.925, 372.575, 341.75, 392.35, 415.2875, 483.15, 524.2, 557.95, 535.6, 761.775, 902.55, 732.325, 803.0, 810.45, 860.65, 816.6, 875.35, 830.35, 849.3, 806.65, 880.1, 926.85, 919.4, 911.95, 899.45, 925.1, 906.9, 904.15, 916.4, 950.55, 928.45, 926.1, 926.7, 916.3, 949.1, 934.25, 923.85, 949.5, 930.7, 894.95, 950.3, 935.85, 928.1, 942.0]}, {"task": "dmc_hopper_stand", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [4.0, 5.369140625, 310.20625, 663.425, 755.8, 822.375, 868.225, 912.8, 910.1, 906.65, 909.65, 900.05, 867.5, 893.45, 926.45, 922.6, 934.85, 899.65, 900.35, 903.15, 888.6, 910.7, 930.0, 921.6, 855.55, 895.15, 904.9, 932.05, 954.5, 923.7, 936.25, 942.55, 934.5, 941.5, 935.85, 932.15, 939.2, 846.6, 929.75, 855.45, 940.1, 939.5, 849.8, 939.15, 934.05, 937.1, 940.95, 945.3, 945.15, 930.9]}, {"task": "dmc_hopper_stand", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 0.8048828125, 3.219091796875, 141.0046875, 317.725, 336.075, 472.675, 800.8, 776.0, 868.65, 914.9, 907.2, 824.65, 923.2, 927.2, 842.95, 944.8, 948.75, 933.8, 923.4, 936.1, 930.35, 904.3, 929.85, 926.65, 933.25, 930.9, 937.15, 932.9, 938.3, 944.25, 934.35, 837.35, 935.65, 915.75, 851.1, 926.45, 930.55, 932.25, 941.4, 930.5, 941.6, 944.55, 946.15, 941.4, 924.85, 934.85, 934.8, 936.75, 954.85]}, {"task": "dmc_hopper_stand", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 5.540625, 121.058984375, 544.375, 715.225, 725.975, 801.8, 917.7, 813.5, 874.35, 909.15, 923.0, 911.15, 932.6, 916.6, 932.85, 926.5, 921.95, 939.95, 934.6, 937.75, 934.0, 947.9, 936.35, 935.35, 947.05, 854.05, 951.05, 925.5, 919.8, 911.5, 933.35, 943.45, 938.25, 934.85, 940.55, 935.1, 917.5, 841.35, 935.25, 932.6, 924.85, 943.0, 936.55, 941.1, 947.45, 932.1, 952.1, 930.7, 937.25]}, {"task": "dmc_hopper_stand", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 1.03984375, 4.404296875, 170.3171875, 361.925, 511.125, 720.05, 796.3, 875.6, 862.2, 921.85, 927.2, 935.8, 930.65, 915.6, 924.2, 930.7, 928.85, 940.2, 926.0, 942.25, 847.85, 926.45, 948.95, 920.2, 945.95, 937.4, 942.8, 931.65, 944.65, 939.35, 940.15, 936.65, 943.2, 942.15, 950.65, 940.5, 936.25, 839.5, 940.75, 937.5, 939.25, 947.05, 905.9, 947.2, 935.35, 940.25, 848.8, 950.1, 928.55]}, {"task": "dmc_hopper_stand", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 0.63984375, 4.41796875, 5.7828125, 201.85, 652.725, 720.95, 814.4, 842.85, 915.9, 878.05, 895.5, 926.3, 932.6, 917.75, 932.5, 922.45, 896.3, 913.5, 934.85, 944.1, 925.3, 913.45, 938.45, 935.0, 936.45, 939.8, 944.65, 928.4, 948.25, 939.35, 949.5, 918.0, 850.95, 949.1, 921.9, 946.35, 916.4, 942.85, 947.8, 935.85, 949.05, 940.45, 942.85, 858.1, 955.2, 939.35, 946.5, 844.85, 949.6]}, {"task": "dmc_acrobot_swingup", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.05804443359375, 57.07297210693359, 84.29622802734374, 204.41171875, 292.3875, 425.675, 350.965625, 375.6, 402.9, 453.875, 442.2375, 500.1125, 422.3, 499.325, 371.425, 388.15, 436.6125, 489.5, 427.25, 461.7, 471.05, 432.0, 494.95, 434.025, 481.4, 453.675, 484.95, 470.275, 406.225, 420.9, 488.5, 419.275, 479.025, 460.8, 399.55, 383.1, 383.725, 389.275, 317.1, 396.9125, 456.225, 401.225, 450.425, 415.1875, 484.15, 430.4125, 368.25, 468.7, 423.325, 407.15]}, {"task": "dmc_acrobot_swingup", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0], "ys": [0.8515625, 42.020166015625, 79.67265625, 185.80859375, 277.95625, 359.375, 346.125, 432.0375, 380.3625, 399.95, 372.0125, 408.75, 485.15, 443.05, 468.575, 396.8, 453.9, 423.30625, 443.2, 556.05, 445.475, 437.1625, 510.15, 517.875, 484.425, 489.05, 490.775, 500.55, 427.675, 468.3625, 493.25, 536.2, 507.975, 525.475, 517.525, 478.275, 493.025, 410.3125, 411.675, 494.4875, 483.45]}, {"task": "dmc_acrobot_swingup", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [149.75, 22.683526611328126, 51.10404663085937, 145.3125, 145.73627319335938, 260.3875, 373.1875, 393.1875, 384.2375, 341.5625, 391.1, 442.7125, 421.5875, 476.85, 486.4, 438.2, 485.625, 490.0125, 443.425, 489.325, 467.25, 524.225, 464.6625, 492.825, 478.425, 484.825, 502.7, 471.425, 450.2, 498.875, 432.475, 505.425, 440.875, 524.1, 494.475, 550.75, 522.825, 433.875, 522.625, 485.5, 518.0, 530.825, 484.425, 527.875, 463.95, 551.225, 492.4, 494.875, 550.075, 497.525]}, {"task": "dmc_acrobot_swingup", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [112.125, 37.519219970703126, 100.0078125, 146.25474243164064, 315.9375, 303.519775390625, 367.9333435058594, 332.7125, 418.8, 411.9625, 414.275, 359.6, 419.0296875, 404.625, 465.7875, 439.725, 452.8625, 397.1, 458.0, 512.9, 539.8, 496.1, 480.0, 489.175, 492.0, 490.9, 495.85, 512.6625, 497.6, 504.35, 513.05, 518.8, 457.5125, 514.15, 529.4, 528.4772727272727, 561.55, 580.825, 539.425, 477.225, 527.8, 469.175, 495.625, 523.875, 476.575, 497.425, 443.125, 535.85, 390.225, 421.6]}, {"task": "dmc_acrobot_swingup", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0], "ys": [7.015625, 26.3669921875, 70.1416015625, 145.29375, 189.79319763183594, 333.8, 371.9, 315.840625, 404.65, 438.2125, 429.375, 411.625, 450.125, 413.6, 391.175, 388.4125, 431.325, 484.0, 468.15, 453.775, 493.4, 466.4, 497.8, 551.575, 502.95, 572.225, 487.8, 514.825, 404.3, 523.525, 518.0, 575.55, 552.425, 589.5, 508.525, 519.275]}, {"task": "dmc_cartpole_swingup_sparse", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 20.8, 428.5, 745.4, 736.3, 790.2, 713.4, 774.9, 784.3, 809.1, 780.5, 802.2, 742.3, 777.2, 795.4, 801.1, 815.8, 801.3, 808.5, 811.2, 793.8, 789.3, 785.1, 819.5, 801.5, 811.9, 786.6, 806.1, 790.1, 810.5, 820.2, 827.5, 817.9, 812.7, 809.7, 758.6, 812.2, 752.8, 711.7, 815.4, 737.2, 724.8, 742.0, 829.4, 817.7, 818.5, 816.8, 814.5, 807.8, 804.1]}, {"task": "dmc_cartpole_swingup_sparse", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 45.7, 494.7, 744.1, 818.8, 807.7, 824.8, 821.0, 793.7, 830.6, 803.3, 837.8, 800.0, 807.8, 785.3, 835.7, 816.0, 820.1, 811.2, 817.4, 789.1, 826.7, 825.8, 827.2, 711.3, 812.9, 838.2, 829.0, 778.5, 816.1, 823.5, 827.0, 811.2, 832.9, 823.6, 824.9, 836.8, 821.7, 772.1, 756.1, 813.9, 828.7, 785.3, 831.9, 816.9, 814.8, 798.0, 794.6, 817.1, 833.1]}, {"task": "dmc_cartpole_swingup_sparse", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 103.4, 430.5, 795.5, 757.3, 825.9, 786.6, 741.5, 815.9, 785.2, 820.9, 799.4, 803.8, 827.0, 827.0, 825.7, 820.2, 827.4, 819.1, 778.5, 622.5, 697.5, 803.5, 759.0, 817.9, 744.0, 746.4, 797.2, 698.2, 801.7, 704.1, 668.1, 750.4, 797.2, 740.9, 789.8, 700.5, 754.4, 641.8, 733.4, 761.2, 763.4, 759.6, 732.1, 746.4, 751.3, 784.4, 687.0, 773.3, 759.8]}, {"task": "dmc_cartpole_swingup_sparse", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 2.0, 139.5, 482.9, 711.1, 777.2, 808.0, 805.0, 795.4, 814.1, 767.5, 817.7, 795.9, 824.3, 816.4, 777.0, 812.5, 830.6, 828.3, 827.7, 830.2, 821.9, 829.3, 831.9, 821.6, 818.0, 815.8, 812.5, 819.1, 826.0, 823.3, 818.2, 818.8, 820.7, 811.2, 821.6, 750.8181818181819, 785.5, 805.0, 647.6, 542.9, 777.0, 783.6, 786.5, 804.7, 816.7, 793.5, 703.9, 791.4, 757.3]}, {"task": "dmc_cartpole_swingup_sparse", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0], "ys": [0.0, 54.3, 419.6, 775.3, 779.6, 797.4, 806.6, 734.0, 806.0, 817.0, 811.5, 794.5, 825.8, 810.2, 758.3, 822.8, 808.4, 827.3, 818.9, 828.8, 821.2, 829.3, 831.0, 812.3, 801.2, 802.1, 781.7, 783.9, 769.4, 746.7, 836.7, 765.4, 651.5, 788.1, 815.3, 694.2, 746.6]}, {"task": "dmc_cartpole_balance_sparse", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [9.0, 638.4, 983.8, 1000.0, 999.8, 998.5, 1000.0, 1000.0, 1000.0, 997.2, 1000.0, 848.0, 982.3, 993.7, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 978.4, 972.4, 1000.0, 1000.0, 1000.0, 983.2, 1000.0, 1000.0, 1000.0, 993.8, 982.0, 832.0, 921.5, 911.6, 925.1, 896.2, 998.6, 806.5, 877.0, 884.9, 992.6, 998.6, 1000.0, 804.6, 962.0, 1000.0, 1000.0, 998.6, 912.5, 958.6, 952.9]}, {"task": "dmc_cartpole_balance_sparse", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0], "ys": [12.0, 557.3, 997.4, 999.5, 998.6, 1000.0, 965.6, 990.8, 989.2, 921.0, 1000.0, 1000.0, 1000.0, 993.6, 981.6, 1000.0, 985.4, 987.7, 918.7, 959.5, 999.5, 873.0, 932.9, 980.2, 945.3, 1000.0, 985.3, 976.4, 982.4, 665.6, 15.6, 14.8, 14.9, 14.4, 12.2, 14.1, 12.3, 12.727272727272727, 13.5, 13.2, 11.9, 12.6, 12.6, 14.0, 19.4]}, {"task": "dmc_cartpole_balance_sparse", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [13.0, 541.4, 998.6, 1000.0, 1000.0, 996.2, 1000.0, 998.5, 999.6, 1000.0, 1000.0, 1000.0, 934.7, 1000.0, 1000.0, 998.5, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 967.3, 869.1, 942.6, 998.4, 998.4, 966.9, 997.4, 904.7, 922.9, 991.4, 1000.0, 1000.0, 816.6, 942.6, 985.3, 992.9, 1000.0, 981.1, 837.0, 44.0, 33.7, 84.0, 624.8, 1000.0, 1000.0, 995.1, 1000.0, 1000.0]}, {"task": "dmc_cartpole_balance_sparse", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [13.0, 702.5, 997.5, 986.1, 998.4, 999.1, 993.5, 996.2, 998.6, 1000.0, 999.8, 923.4, 936.9, 999.8, 1000.0, 995.6, 997.3, 976.5, 1000.0, 967.9, 1000.0, 1000.0, 915.0, 1000.0, 994.7, 1000.0, 971.6, 968.0, 996.3, 915.7, 904.9, 908.5, 983.7272727272727, 1000.0, 1000.0, 1000.0, 998.9, 997.2, 999.1, 967.5, 965.9, 982.3, 989.3, 968.0, 999.4, 999.3, 999.9, 978.2, 1000.0, 333.5]}, {"task": "dmc_cartpole_balance_sparse", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0], "ys": [9.0, 617.7, 1000.0, 917.8, 990.6, 994.8, 949.0, 999.7, 1000.0, 992.3, 1000.0, 1000.0, 998.7, 998.6, 987.1, 1000.0, 1000.0, 999.3, 1000.0, 951.5, 951.5, 999.4, 972.0, 927.8, 948.1, 1000.0, 1000.0, 928.1, 973.6, 987.3, 1000.0, 1000.0, 981.8, 1000.0, 1000.0]}, {"task": "dmc_walker_run", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [4.03125, 90.6359375, 178.575, 235.9125, 293.75, 359.953125, 557.2, 605.8, 636.1, 687.3, 691.7, 741.65, 736.4, 755.55, 757.0, 756.7, 754.25, 778.15, 790.4, 787.35, 637.71796875, 771.6, 792.7, 666.35, 787.1, 812.25, 799.55, 799.05, 807.6, 792.75, 797.55, 809.9, 792.9, 793.85, 806.45, 810.2, 817.25, 813.05, 813.35, 820.1, 809.55, 809.15, 820.15, 806.85, 814.9, 818.5, 811.5, 823.2, 826.7, 813.4]}, {"task": "dmc_walker_run", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [19.84375, 42.9890625, 157.01875, 235.8875, 290.825, 420.675, 533.7, 611.95, 625.7, 640.6, 643.1, 714.25, 738.9, 748.85, 763.5, 751.5, 767.65, 695.5609375, 775.7, 790.65, 805.25, 809.85, 800.9, 812.8, 792.55, 811.0, 815.5, 807.3, 815.65, 806.0, 809.15, 823.0, 821.5, 824.15, 823.55, 821.7, 818.7, 823.8, 840.95, 829.7, 788.3, 822.25, 822.3, 835.1, 834.3, 821.85, 833.2, 825.45, 836.8, 829.7]}, {"task": "dmc_walker_run", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [14.2890625, 65.8890625, 167.85, 286.9125, 446.725, 587.4, 628.65, 652.3, 683.1, 728.9, 750.45, 779.5, 783.15, 783.5, 796.8, 777.05, 808.4, 804.9, 808.0, 798.35, 804.65, 811.95, 801.7, 797.6, 804.45, 808.95, 807.55, 813.95, 809.2, 830.55, 810.7, 822.5, 820.5, 825.7, 815.65, 816.35, 821.85, 817.8, 830.5, 829.0, 820.4, 822.4, 825.9, 820.0, 822.45, 814.65, 823.4, 818.0, 818.5, 823.55]}, {"task": "dmc_walker_run", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [16.8125, 112.1546875, 210.7125, 279.7375, 329.125, 419.725, 566.45, 609.425, 684.6, 729.6, 742.85, 764.95, 778.15, 761.3, 779.05, 799.15, 799.25, 799.0, 799.75, 806.8, 811.2, 811.55, 812.95, 813.25, 811.8, 814.15, 800.5, 811.65, 807.1, 807.4, 807.15, 813.85, 808.2, 808.0, 817.9, 807.8, 803.55, 815.9, 811.25, 826.2, 812.45, 809.95, 824.2, 822.3, 812.4, 817.5, 821.25, 817.15, 823.45, 826.25]}, {"task": "dmc_walker_run", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [44.1875, 101.54375, 222.6625, 355.5, 432.8, 529.725, 612.775, 688.7, 729.7, 749.65, 761.75, 774.65, 773.65, 776.85, 789.4, 774.4, 779.4, 780.25, 770.75, 789.1, 776.8, 781.6, 787.8, 794.9, 790.35, 796.1, 790.4, 794.5, 798.55, 797.1, 793.45, 804.45, 813.95, 796.8, 812.95, 809.0, 821.3, 808.15, 806.2, 803.5, 802.3, 820.9, 804.55, 809.25, 809.7, 819.6, 815.75, 803.25, 826.2, 821.4]}, {"task": "dmc_hopper_hop", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.006755828857421875, 0.1185028076171875, 0.6159820556640625, 31.586579513549804, 62.715625, 142.85, 181.9375, 200.2625, 205.625, 230.1875, 254.85, 259.2125, 259.9375, 264.125, 298.325, 299.05, 297.975, 308.65, 316.9, 303.1625, 315.875, 276.375, 323.375, 328.55, 321.8, 292.275, 328.375, 328.975, 292.05, 329.925, 324.875, 334.125, 303.375, 344.925, 337.725, 334.8, 349.275, 343.675, 350.275, 350.75, 357.85, 345.375, 344.375, 345.0, 359.35, 352.15, 357.975, 348.15, 353.725, 339.575]}, {"task": "dmc_hopper_hop", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.00522613525390625, 0.0006381988525390625, 0.007147216796875, 2.3416015625, 20.80625, 78.796875, 116.71875, 175.9125, 192.0375, 202.95, 210.95, 213.6625, 233.575, 244.6625, 222.05, 261.8125, 282.2, 280.25, 276.7875, 283.35, 281.3, 280.775, 289.875, 299.975, 304.0, 294.0875, 302.85, 298.425, 265.675, 286.2375, 295.7, 295.25, 293.6125, 297.275, 315.275, 313.325, 308.925, 298.225, 317.475, 330.125, 327.475, 323.9, 326.9, 318.9, 319.25, 316.875, 317.1, 309.125, 320.15, 309.7]}, {"task": "dmc_hopper_hop", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 0.0, 1.310009765625, 25.66953125, 69.43125, 84.734375, 100.69375, 139.625, 180.4125, 206.25, 228.4, 248.65, 252.55, 276.575, 295.425, 306.0, 313.9, 279.0375, 316.4, 318.05, 321.45, 327.625, 337.875, 315.075, 385.925, 440.45, 424.325, 472.575, 455.725, 492.475, 500.825, 452.95, 506.325, 490.575, 467.575, 516.95, 509.575, 530.9, 544.875, 556.65, 517.3875, 583.8, 575.4, 575.1, 612.85, 614.7, 592.275, 609.0, 606.45, 620.35]}, {"task": "dmc_hopper_hop", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 1.80775146484375, 47.721484375, 104.73125, 145.7125, 189.85, 215.4125, 241.675, 282.1375, 254.5125, 291.85, 304.4125, 297.3125, 311.9, 321.1, 332.225, 320.5, 317.175, 320.4, 305.75, 322.45, 312.875, 324.05, 329.6, 328.025, 336.725, 333.475, 338.85, 300.8, 301.4875, 322.05, 334.65, 340.475, 371.225, 337.825, 377.825, 379.075, 379.25, 369.525, 393.025, 379.025, 358.4, 341.95, 375.025, 409.5, 415.5, 490.3, 530.15, 520.1, 548.225]}, {"task": "dmc_hopper_hop", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0], "ys": [0.0, 0.00049285888671875, 0.61513671875, 5.3861328125, 49.38515625, 103.88125, 176.55, 214.875, 290.9375, 328.7, 342.175, 336.8, 273.4875, 367.45, 360.825, 382.475, 454.9, 474.075, 458.25, 489.75, 501.1, 498.5, 547.625, 549.4, 541.9, 468.675, 563.8, 595.2, 542.175, 574.4, 596.0, 590.3, 609.85, 627.75]}, {"task": "dmc_walker_stand", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [357.5, 281.6125, 785.95, 876.55, 949.6, 954.95, 961.95, 941.45, 932.25, 945.65, 936.9, 906.75, 973.3, 958.25, 964.45, 937.25, 971.25, 968.5, 979.2, 973.35, 965.1, 973.1, 974.6, 982.65, 969.1, 979.9, 973.5, 985.6, 980.9, 976.95, 985.95, 988.35, 897.425, 976.15, 878.50625, 963.4, 943.15, 968.75, 970.45, 971.85, 970.25, 983.9, 904.125, 964.7, 956.05, 895.3375, 985.5, 984.3, 979.8, 903.525]}, {"task": "dmc_walker_stand", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [236.375, 252.7875, 700.95, 819.65, 918.35, 934.2, 965.55, 972.15, 962.3, 967.45, 966.0, 958.5, 925.75, 986.75, 970.4, 977.25, 893.75, 978.4, 980.4, 948.6, 939.9, 972.85, 958.1, 964.3, 939.3, 882.9625, 952.5, 971.8, 973.7, 964.2, 975.85, 939.65, 988.75, 966.85, 948.05, 938.2, 980.1, 963.3, 866.65, 922.9, 976.75, 977.25, 974.4, 973.2, 972.65, 980.55, 991.45, 972.05, 975.9, 857.35]}, {"task": "dmc_walker_stand", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [159.75, 313.48125, 669.3, 918.1, 940.7, 958.75, 965.75, 956.7, 972.05, 974.15, 959.45, 974.3, 977.05, 970.7, 966.2, 909.45, 961.15, 984.65, 974.5, 962.25, 980.8, 969.15, 983.85, 985.85, 984.9, 980.1, 985.35, 986.6, 987.7, 964.05, 963.05, 982.05, 970.7, 983.25, 979.4, 982.35, 888.925, 980.05, 977.9, 981.4, 987.3, 977.1, 886.85625, 967.75, 903.1375, 886.675, 983.6, 975.45, 990.65, 968.8]}, {"task": "dmc_walker_stand", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [91.375, 448.071875, 853.85, 963.05, 949.95, 979.75, 969.6, 970.95, 979.8, 911.775, 955.5, 971.4, 968.25, 973.05, 978.1, 972.0, 974.15, 981.85, 971.85, 977.85, 962.95, 890.875, 977.9, 978.55, 974.4, 964.7, 983.75, 978.65, 973.1, 982.25, 985.6, 978.9, 971.35, 982.2, 973.55, 983.45, 985.55, 896.1, 984.6, 967.0, 982.65, 962.2, 971.4, 971.05, 984.1, 974.05, 975.75, 979.65, 975.5, 977.35]}, {"task": "dmc_walker_stand", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [341.0, 279.89375, 605.15, 730.85, 870.1, 972.25, 971.1, 968.15, 962.4, 802.009375, 980.35, 979.85, 895.10625, 979.7, 982.35, 969.55, 977.3, 977.35, 978.8, 902.0625, 978.2, 976.3, 977.7, 974.0, 969.4, 980.65, 976.25, 991.95, 895.7875, 984.9, 968.25, 981.35, 968.55, 987.05, 976.75, 969.4, 982.1, 983.65, 979.6, 974.5, 975.1, 987.6, 991.4, 967.05, 983.15, 972.1, 978.75, 978.65, 987.8, 981.1]}, {"task": "dmc_cartpole_balance", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [135.75, 445.575, 847.05, 980.2, 988.6, 978.3, 978.15, 988.3, 990.6, 987.2, 992.4, 971.4, 964.2, 984.4, 984.0, 991.35, 994.9, 985.1, 981.55, 987.05, 998.4, 992.0, 997.25, 997.4, 942.225, 997.0, 996.6, 997.15, 997.5, 995.15, 994.7, 995.6, 996.3, 996.65, 997.1, 996.0, 910.05, 991.9, 994.95, 992.95, 997.15, 964.3, 996.9, 996.85, 996.4, 991.8, 956.3, 616.725, 203.8375, 251.2]}, {"task": "dmc_cartpole_balance", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0], "ys": [136.125, 418.5625, 865.5, 971.4, 978.5, 988.85, 987.55, 994.35, 994.05, 996.95, 989.1, 994.2, 996.2, 992.2, 992.85, 994.6, 997.4, 959.35, 997.0, 964.05, 997.2, 996.4, 996.8, 998.0, 991.5, 997.15, 992.2, 997.85, 958.85, 992.35, 993.5, 997.25, 946.15, 994.8, 926.8, 996.7727272727273, 986.3, 997.6, 998.9, 998.2, 998.2, 911.45, 921.25]}, {"task": "dmc_cartpole_balance", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [134.625, 529.4375, 798.15, 905.45, 969.35, 990.6, 970.85, 993.0, 995.1, 976.9, 995.65, 993.25, 972.45, 991.0, 954.7, 997.85, 997.4, 998.35, 996.5, 997.2, 997.25, 994.9, 996.7, 995.8, 997.5, 994.6, 997.4, 902.95, 992.75, 994.85, 996.45, 996.0, 914.5, 942.975, 951.4, 998.2, 996.35, 997.05, 946.225, 998.35, 995.6, 875.675, 962.15, 996.2, 951.9, 996.55, 988.35, 928.525, 918.925, 907.25]}, {"task": "dmc_cartpole_balance", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [135.5, 474.825, 807.15, 939.3, 971.85, 972.75, 992.15, 992.15, 993.4, 992.9, 992.4, 997.45, 996.85, 996.0, 997.5, 997.8, 997.7, 996.7, 997.95, 949.3, 978.4, 997.65, 984.55, 997.45, 997.9, 998.45, 997.5, 998.0, 998.05, 998.5, 998.15, 997.95, 998.15, 998.95, 998.4, 998.75, 998.1, 997.9, 998.35, 997.3, 991.55, 801.45, 881.4, 997.1, 987.7, 991.4, 944.05, 997.75, 995.7, 892.6]}, {"task": "dmc_cartpole_balance", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [136.0, 493.15, 816.6, 981.85, 987.9, 978.35, 983.65, 994.0, 987.25, 990.3, 971.8, 989.9, 977.75, 990.85, 995.3, 963.9, 982.0, 937.45, 989.15, 997.65, 899.725, 981.9, 983.35, 987.7, 995.35, 995.0, 951.2, 991.0, 977.75, 994.2, 947.2, 944.45, 987.05, 989.75, 988.05, 995.0, 994.8, 997.75, 959.05, 994.35, 993.45, 996.05, 992.9, 991.9, 787.975, 280.25, 269.95, 250.9375, 234.125, 234.9125]}, {"task": "dmc_finger_turn_easy", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [1000.0, 299.8, 198.4, 387.2, 359.7, 240.4, 576.7, 731.4, 698.8, 735.3, 815.4, 854.7, 924.5, 935.0, 961.7, 966.9, 962.6, 958.8, 959.4, 951.4, 966.1, 945.7, 963.2, 958.1, 884.3, 971.9, 762.0, 925.9, 947.7, 942.4, 964.4, 965.2, 941.8, 970.5, 946.9, 971.5, 870.2, 961.3, 868.2, 861.7, 981.3, 963.6, 880.9, 957.3, 874.2, 868.9, 977.3, 976.6, 976.1, 985.4]}, {"task": "dmc_finger_turn_easy", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 100.0, 573.0, 368.3, 492.2, 421.5, 549.5, 728.3, 588.4, 731.0, 858.2, 961.4, 952.8, 935.9, 940.3, 857.0, 844.7, 983.0, 878.4, 856.7, 820.9, 889.2, 812.5, 817.9, 947.2, 873.7, 800.9, 884.4, 879.6, 889.2, 875.9, 711.8, 964.3, 750.2, 914.6, 847.5, 877.5, 820.5, 883.8, 873.4, 941.2, 963.0, 964.2, 975.1, 979.3, 956.7, 921.0, 882.1, 942.2, 943.5]}, {"task": "dmc_finger_turn_easy", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [1000.0, 112.9, 185.8, 300.8, 288.4, 480.6, 810.4, 520.1, 341.4, 629.6, 757.6, 700.8, 649.9, 853.6, 861.1, 960.5, 863.8, 939.0, 956.2, 950.3, 889.7, 958.3, 863.3, 915.1, 968.5, 901.1, 942.2, 972.8, 869.1, 980.4, 849.4, 886.8, 953.6, 906.4, 843.7, 970.3, 779.8, 884.6, 851.8, 963.5, 886.9, 964.0, 787.5, 876.8, 957.7, 851.9, 974.5, 970.8, 952.5, 851.7]}, {"task": "dmc_finger_turn_easy", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 54.8, 215.2, 628.5, 587.3, 478.3, 343.7, 646.7, 623.4, 498.3, 668.4, 613.7, 838.5, 705.2, 712.2, 781.3, 618.5, 679.5, 725.6, 825.2, 682.1, 750.3, 757.8, 943.3, 825.4, 771.2, 685.6, 848.7, 664.5, 933.8, 903.4, 967.9, 777.7, 794.0, 932.2, 755.7, 947.2, 892.1, 923.1, 782.6, 960.7, 778.1, 821.3, 967.4, 946.4, 847.4, 929.7, 966.1, 960.7, 922.0]}, {"task": "dmc_finger_turn_easy", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 86.5, 182.0, 631.5, 169.5, 749.4, 420.9, 684.6, 855.1, 862.6, 806.0, 869.7, 938.3, 946.7, 848.3, 963.4, 950.3, 957.6, 875.4, 935.2, 934.5, 966.5, 970.0, 955.8, 964.3, 963.9, 944.0, 959.1, 898.3, 973.2, 943.6, 954.2, 958.6, 964.8, 974.5, 957.5, 972.6, 984.7, 940.8, 955.1, 963.7, 952.7, 949.7, 855.1, 959.1, 968.8, 965.4, 925.9, 948.1, 962.2]}, {"task": "dmc_quadruped_run", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [13.28125, 136.887255859375, 162.5984375, 288.771875, 203.784375, 308.55, 311.35, 357.3, 439.625, 423.1625, 500.225, 594.45, 607.35, 621.275, 740.525, 743.0, 836.15, 824.225, 725.725, 872.25, 864.9, 894.45, 912.55, 818.35, 857.6, 850.95, 877.25, 887.1, 916.45, 896.0, 904.1, 919.4, 900.75, 900.4, 907.05, 901.3, 904.35, 891.05, 915.15, 925.55, 911.6, 926.35, 940.2, 928.45, 946.3, 905.45, 920.6, 904.95, 913.7, 915.95]}, {"task": "dmc_quadruped_run", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0], "ys": [456.0, 68.16875, 109.1046875, 191.44375, 270.20625, 281.18125, 291.775, 323.8375, 343.775, 414.075, 398.0625, 367.5625, 430.0625, 428.975, 496.775, 674.5, 753.3, 766.7, 766.3, 789.85, 810.25, 794.725, 827.475, 893.0, 855.65, 851.55, 802.0, 877.85, 898.95, 920.8, 876.6, 934.5, 927.75, 894.75, 893.5, 933.1, 849.7]}, {"task": "dmc_quadruped_run", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.6904296875, 34.6921875, 100.825, 46.2890625, 103.65234375, 137.015625, 228.4625, 186.74375, 287.325, 311.6875, 270.3, 412.0125, 408.35, 417.125, 398.75, 361.175, 384.925, 382.55, 407.25, 455.0, 492.25, 575.875, 596.325, 679.25, 697.85, 754.95, 673.45, 800.5, 785.55, 809.575, 860.45, 881.25, 879.1, 875.35, 887.25, 898.2, 836.6, 880.0, 881.95, 871.4, 789.4, 843.05, 879.95, 884.85, 827.9, 850.55, 861.85, 864.65, 858.35, 814.0]}, {"task": "dmc_quadruped_run", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [229.25, 65.44375, 100.7203125, 114.68125, 144.25, 105.04521484375, 115.5140625, 153.052490234375, 159.315625, 244.465625, 360.75, 350.8, 323.05, 350.875, 380.65, 380.025, 376.9625, 373.625, 376.025, 437.175, 511.275, 599.575, 640.8, 720.3, 732.525, 791.2, 781.175, 784.5, 755.175, 849.8, 830.25, 838.25, 910.4, 863.3, 914.25, 920.1, 901.05, 875.15, 929.0, 924.65, 927.0, 906.3, 908.2, 917.45, 924.05, 891.0, 941.55, 920.05, 937.55, 938.35]}, {"task": "dmc_quadruped_run", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0], "ys": [18.828125, 33.2078125, 134.2328125, 88.4578125, 109.640625, 171.25, 238.425, 339.2375, 398.475, 349.125, 413.15, 368.475, 306.9, 367.025, 345.975, 417.025, 432.125, 412.425, 517.675, 529.025, 616.325, 757.0, 745.05, 886.75, 905.25, 840.95, 896.4, 897.95, 893.35, 771.325, 833.85, 896.75, 900.3]}, {"task": "dmc_cheetah_run", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.27783203125, 78.90673828125, 341.18125, 614.8, 605.725, 647.475, 625.325, 572.675, 638.75, 617.125, 747.35, 798.2, 828.55, 816.35, 878.65, 783.95, 804.55, 864.55, 842.95, 844.95, 849.65, 869.35, 845.15, 830.6, 870.3, 849.9, 878.6, 876.5, 876.0, 837.65, 831.9, 844.8, 872.2, 842.6, 856.8, 875.65, 875.65, 874.0, 871.1, 886.15, 870.4, 866.15, 848.65, 877.9, 862.75, 874.85, 861.65, 875.45, 868.55, 867.15]}, {"task": "dmc_cheetah_run", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [2.75390625, 223.03671875, 565.275, 601.25, 618.6875, 627.35625, 656.6625, 668.0125, 749.85, 791.5, 673.525, 738.3, 698.09375, 765.675, 837.8, 867.05, 834.15, 857.8, 825.05, 777.25, 818.35, 868.6, 891.05, 865.9, 842.75, 871.1, 870.85, 890.3, 865.0, 903.1, 901.15, 893.6, 866.6, 899.65, 854.55, 899.6, 872.55, 857.2, 890.9, 863.35, 873.1, 881.05, 875.0, 890.45, 864.6, 875.6, 875.95, 861.85, 886.65, 866.2]}, {"task": "dmc_cheetah_run", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [4.5546875, 91.2501953125, 245.590625, 581.175, 668.45, 661.85, 716.55, 725.8, 720.65, 760.6, 762.25, 798.95, 826.2, 816.45, 727.8, 809.7, 795.85, 883.6, 842.3, 851.15, 800.0, 840.1, 841.9, 835.05, 874.45, 875.8, 897.85, 887.9, 878.15, 855.975, 889.2, 858.55, 901.1, 902.05, 884.25, 880.15, 891.1, 904.4, 895.2, 840.85, 845.15, 873.0, 895.0, 874.4, 867.0, 895.2, 876.6, 892.45, 879.05, 896.3]}, {"task": "dmc_cheetah_run", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [3.908203125, 135.6875, 447.6, 613.2, 602.025, 651.825, 697.7, 687.55, 715.8, 705.2, 656.55, 698.1, 693.15, 691.9, 715.75, 697.55, 743.85, 767.1, 739.65, 774.2, 765.65, 774.8, 767.1, 757.15, 775.65, 755.15, 815.15, 834.95, 875.35, 864.05, 893.45, 845.45, 847.75, 870.1, 877.1, 883.4, 859.05, 874.35, 883.75, 899.75, 888.7, 881.2, 893.3, 894.6, 883.9, 879.35, 845.3, 875.6, 897.85, 829.975]}, {"task": "dmc_cheetah_run", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.450439453125, 109.3404296875, 325.46875, 463.09375, 572.4625, 561.65, 653.375, 653.85, 614.45, 702.0, 724.4, 703.5, 735.15, 735.2, 681.8, 763.95, 738.7, 732.2, 738.45, 781.2, 714.475, 793.55, 762.0, 810.6, 801.45, 826.0, 879.45, 854.15, 850.05, 872.0, 881.35, 878.85, 882.95, 880.15, 872.95, 877.5, 856.45, 838.45, 868.15, 885.0, 857.15, 903.3, 875.95, 858.3, 847.75, 877.5, 896.65, 886.5, 871.9, 888.6]}, {"task": "dmc_finger_spin", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 22.3, 332.9, 411.7, 403.3, 300.3, 360.6, 355.2, 399.3, 945.3, 627.5, 468.0, 430.7, 460.8, 409.7, 369.2, 257.0, 323.0, 453.9, 588.3, 593.0, 426.0, 449.6, 316.4, 550.1, 418.4, 454.8, 602.6, 553.4, 322.0, 399.7, 395.3, 333.4, 605.5, 622.6, 704.5, 652.0, 683.9, 192.0, 205.2, 307.7, 470.1, 501.3, 449.1, 397.9, 522.3, 377.6, 368.8, 356.8, 447.3]}, {"task": "dmc_finger_spin", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 0.1, 0.0, 0.0, 16.4, 271.2, 329.3, 321.1, 341.1, 334.0, 320.2, 327.8, 331.0, 336.5, 326.3, 326.5, 338.3, 323.7, 313.4, 282.3, 284.8, 190.0, 238.0, 274.7, 186.7, 139.9, 185.0, 79.2, 86.1, 144.6, 183.6, 138.2, 219.9, 209.7, 188.4, 220.2, 203.6, 181.6, 128.2, 120.4, 126.5, 150.1, 206.1, 120.7, 154.7, 197.7, 161.2, 181.3, 150.5, 167.4]}, {"task": "dmc_finger_spin", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 12.4, 238.8, 394.4, 406.6, 426.8, 535.0, 654.1, 668.6, 825.9, 862.4, 894.5, 675.5, 738.4, 843.3, 663.9, 807.9, 732.9, 699.3, 698.9, 971.7, 984.4, 977.8, 979.4, 977.8, 980.2, 984.2, 982.7, 981.3, 976.5, 978.7, 976.9, 976.4, 833.9, 914.4, 276.4, 530.6, 542.4, 636.0, 459.4, 544.2, 408.1, 563.9, 463.4, 464.0, 553.6, 380.7, 363.7, 430.8, 531.1]}, {"task": "dmc_finger_spin", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 2.5, 51.9, 353.8, 368.8, 367.9, 392.4, 376.2, 432.9, 362.1, 428.6, 446.2, 389.9, 308.9, 345.4, 339.1, 223.1, 294.1, 407.2, 436.0, 466.0, 500.3, 532.9, 490.6, 531.9, 566.6, 624.9, 616.2, 323.2, 571.0, 615.9, 618.6, 336.8, 211.3, 278.0, 268.1, 323.4, 330.4, 395.7, 453.3, 427.1, 565.0, 589.3, 592.3, 574.0, 514.2, 395.9, 454.7, 399.1, 457.1]}, {"task": "dmc_finger_spin", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 2.8, 0.5, 0.0, 186.9, 326.6, 389.5, 400.0, 399.0, 377.4, 334.2, 398.2, 391.0, 308.6, 374.9, 277.3, 384.7, 323.4, 285.6, 129.9, 0.3, 188.0, 97.2, 304.1, 249.2, 277.6, 216.1, 184.7, 234.4, 308.8, 281.5, 306.5, 343.2, 274.9, 251.0, 268.7, 340.9, 423.3, 404.3, 383.8, 97.9, 384.5, 337.7, 361.6, 325.9, 250.7, 439.0, 384.1, 358.6, 564.5]}, {"task": "dmc_walker_walk", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [30.328125, 173.3328125, 592.075, 820.25, 903.3, 921.2, 946.8, 936.4, 947.0, 932.85, 963.25, 961.45, 874.340625, 956.35, 960.7, 958.95, 959.85, 967.95, 954.7, 965.9, 976.25, 952.1, 970.25, 962.0, 960.7, 965.9, 929.3, 961.7, 965.6, 966.8, 966.95, 956.15, 971.6, 930.25, 841.05, 848.75, 916.9, 966.5, 971.05, 959.75, 968.35, 968.3, 970.8, 959.5, 959.55, 879.7890625, 964.85, 967.45, 969.2, 979.15]}, {"task": "dmc_walker_walk", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [15.2578125, 81.34609375, 406.7625, 659.175, 781.95, 885.4, 929.6, 946.75, 859.496875, 955.45, 971.0, 961.0, 957.65, 935.6, 926.1, 918.7, 946.85, 925.6, 937.3, 915.8, 965.4, 876.9984375, 965.4, 953.7, 947.4, 969.15, 933.4, 862.9078125, 965.1, 970.9, 961.8, 961.8, 958.4, 972.25, 971.6, 897.05, 902.9, 936.9, 941.95, 945.55, 962.25, 965.5, 970.3, 971.85, 939.8, 857.8, 880.95, 899.8, 926.05, 890.25]}, {"task": "dmc_walker_walk", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [29.90625, 232.71875, 589.2, 823.25, 856.7, 909.3, 926.25, 956.35, 942.35, 957.35, 959.85, 967.3, 969.8, 970.7, 977.7, 959.5, 950.85, 969.2, 966.4, 953.3, 968.3, 970.15, 967.45, 966.25, 959.55, 970.25, 974.45, 970.15, 979.45, 956.5, 964.6, 964.0, 946.9, 960.6, 977.8, 970.85, 968.1, 967.9, 965.9, 960.0, 967.05, 886.2, 966.3, 964.3, 964.8, 969.3, 962.85, 968.2, 967.65, 971.8]}, {"task": "dmc_walker_walk", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [36.3125, 88.1796875, 480.825, 690.0, 739.6, 842.0, 887.7, 943.0, 940.3, 944.4, 940.5, 958.8, 961.35, 961.15, 964.7, 964.75, 974.9, 964.45, 966.35, 872.78125, 967.3, 964.4, 973.15, 971.9, 966.3, 970.5, 962.75, 963.4, 973.05, 966.4, 970.75, 968.15, 938.35, 973.35, 971.8, 961.55, 968.75, 972.05, 959.85, 923.6, 915.65, 865.6, 837.9, 873.65, 938.35, 976.45, 975.95, 972.45, 969.5, 965.75]}, {"task": "dmc_walker_walk", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0], "ys": [17.4375, 110.3671875, 473.0, 621.45, 767.35, 871.15, 934.8, 943.55, 957.0, 953.05, 943.35, 957.45, 965.15, 964.95, 963.5, 948.6, 961.65, 969.9, 962.2, 971.3, 969.1, 970.9, 972.9, 975.5, 978.3, 962.1, 964.8, 970.45, 966.5454545454545, 980.15, 965.15, 966.35, 972.05]}, {"task": "dmc_reacher_easy", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 123.2, 414.5, 576.7, 765.1, 548.9, 483.3, 534.1, 281.5, 684.0, 485.7, 714.0, 579.8, 670.1, 840.9, 870.5, 942.4, 772.2, 686.7, 967.0, 877.2, 871.7, 855.1, 949.6, 877.6, 962.3, 971.5, 775.4, 871.8, 977.8, 974.8, 980.2, 955.9, 971.1, 979.5, 963.8, 978.4, 877.0, 977.3, 973.7, 939.8, 968.7, 887.7, 979.0, 935.9, 978.9, 954.3, 983.3, 971.1, 982.0]}, {"task": "dmc_reacher_easy", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0], "ys": [0.0, 56.3, 118.9, 196.5, 355.6, 586.4, 669.9, 599.3, 602.0, 578.7, 653.0, 679.2, 690.6, 873.9, 692.9, 687.7, 981.2, 777.1, 975.3, 972.6, 967.7, 849.5, 877.1, 881.4, 874.6, 880.2, 969.3, 777.6, 983.6, 933.9, 971.9, 976.5, 969.9, 980.4, 879.8, 973.6, 959.8, 972.2, 971.6, 974.5, 973.0, 970.6, 982.2, 976.3, 968.2]}, {"task": "dmc_reacher_easy", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [86.0, 149.1, 117.7, 480.5, 477.9, 316.9, 641.9, 449.3, 654.1, 676.4, 855.0, 805.4, 429.0, 790.1, 686.6, 729.2, 602.4, 739.6, 961.8, 747.0, 765.7, 969.6, 845.0, 873.4, 945.2, 949.7, 878.1, 973.3, 958.7, 778.2, 889.5, 979.1, 967.6, 872.0, 883.1, 970.1, 978.1, 785.9, 865.2, 974.6, 874.8, 975.3, 974.7, 880.4, 964.1, 867.5, 784.2, 972.0, 977.1, 975.8]}, {"task": "dmc_reacher_easy", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [393.0, 171.9, 434.9, 478.0, 451.8, 119.3, 544.6, 580.8, 745.1, 504.6, 506.9, 498.8, 640.5, 527.7, 498.2, 768.2, 645.7, 767.4, 875.3, 763.5, 758.3, 907.6, 960.1, 769.4, 942.5, 921.1, 940.5, 975.8, 894.9, 973.8, 974.7, 964.6, 969.1, 872.2, 978.7, 878.7272727272727, 967.5, 974.4, 875.7, 972.3, 974.9, 883.4, 971.3, 964.9, 879.9, 974.9, 879.4, 966.9, 961.1, 971.1]}, {"task": "dmc_reacher_easy", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0], "ys": [0.0, 123.5, 108.8, 390.9, 499.6, 576.1, 617.7, 388.1, 562.6, 865.0, 512.8, 602.2, 470.4, 578.9, 681.5, 411.8, 975.9, 579.7, 783.4, 582.6, 915.7, 860.9, 867.6, 970.3, 971.6, 947.4, 973.7, 975.0, 973.4, 879.9, 969.6, 859.6, 945.4, 974.6, 877.3, 895.0, 970.7, 783.9]}, {"task": "dmc_cup_catch", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 168.0, 395.9, 910.7, 913.4, 956.3, 960.4, 953.8, 968.0, 966.7, 968.2, 965.8, 973.0, 972.4, 971.7, 971.1, 969.7, 968.7, 977.9, 976.9, 962.8, 978.6, 972.8, 971.3, 969.9, 973.7, 980.4, 977.4, 975.8, 973.4, 960.5, 973.3, 973.0, 880.7, 971.6, 972.7, 942.1, 970.7, 964.0, 974.4, 973.0, 964.3, 872.0, 968.9, 845.0, 941.4, 935.9, 970.6, 972.3, 950.8]}, {"task": "dmc_cup_catch", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 0.0, 713.7, 938.0, 940.6, 967.8, 969.8, 972.3, 973.0, 971.3, 974.6, 967.9, 968.0, 971.5, 966.2, 968.2, 974.8, 973.0, 955.7, 966.6, 897.4, 970.0, 916.0, 975.4, 976.7, 963.8, 971.4, 976.1, 963.5, 974.2, 969.4, 974.0, 965.5, 970.8, 976.5, 974.7, 969.7, 968.7, 951.2, 964.8, 968.4, 969.6, 969.8, 980.1, 970.5, 974.1, 977.7, 959.1, 974.7, 968.1]}, {"task": "dmc_cup_catch", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 0.0, 668.0, 908.6, 962.4, 962.4, 957.7, 970.6, 968.1, 969.4, 963.5, 969.4, 969.3, 965.1, 968.8, 967.8, 968.3, 970.9, 969.8, 968.7, 964.3, 960.5, 970.6, 975.3, 971.4, 968.0, 970.0, 968.3, 962.9, 973.6, 943.1, 977.0, 964.3, 952.1, 975.4, 943.3, 956.8, 975.3, 961.2, 965.7, 965.8, 967.6, 972.1, 970.9, 957.9, 972.0, 947.9, 965.2, 973.8, 957.5]}, {"task": "dmc_cup_catch", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 0.0, 544.8, 799.4, 954.3, 966.3, 959.8, 964.6, 965.5, 973.3, 971.0, 975.8, 967.0, 976.6, 966.2, 966.3, 973.3, 973.8, 867.3, 978.1, 920.1, 967.3, 963.7, 970.1, 967.1, 962.2, 968.1, 974.7, 968.8, 968.4, 967.5, 971.1, 976.2, 967.9, 977.4, 980.1, 976.2, 969.3, 974.0, 970.0, 972.2, 966.4, 939.0, 972.5, 972.1, 954.3, 975.5, 968.0, 973.8, 968.4]}, {"task": "dmc_cup_catch", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 199.4, 191.9, 804.5, 893.7, 955.9, 951.6, 962.4, 960.4, 964.0, 958.2, 971.5, 970.3, 966.8, 961.7, 969.2, 975.4, 967.5, 969.8, 977.7, 971.7, 971.6, 971.6, 959.2, 972.2, 971.7, 967.5, 975.5, 961.4, 979.2, 963.3, 974.2, 973.0, 969.5, 976.7, 970.6, 972.1, 973.5, 967.5, 951.7, 974.6, 968.5, 974.1, 969.3, 968.8, 963.7, 970.6, 970.2, 963.6, 959.7]}, {"task": "dmc_finger_turn_hard", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 0.6, 145.0, 277.3, 225.3, 357.6, 428.1, 329.4, 441.2, 476.8, 839.1, 774.7, 742.7, 934.0, 845.3, 703.8, 723.2, 861.1, 898.2, 849.1, 977.6, 957.9, 954.6, 852.5, 964.5, 965.7, 874.7, 899.6, 971.0, 837.0, 935.8, 897.5, 966.0, 957.6, 864.6, 962.9, 960.2, 962.7, 970.3, 897.3, 858.6, 962.3, 792.4, 870.1, 778.4, 963.1, 967.0, 969.8, 812.7, 870.7]}, {"task": "dmc_finger_turn_hard", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [14.0, 98.2, 105.6, 276.1, 187.2, 254.1, 634.3, 194.3, 377.2, 889.2, 866.9, 624.5, 763.7, 752.5, 809.5, 564.6, 767.6, 887.1, 949.3, 917.3, 863.3, 910.0, 814.7, 931.2, 883.0, 869.0, 934.7, 626.4, 709.4, 965.5, 593.5, 642.1, 682.3, 821.6, 955.9, 951.4, 862.3, 964.2, 868.2, 948.5, 938.0, 960.0, 958.1, 945.2, 856.0, 966.1, 958.0, 675.2, 971.8, 862.3]}, {"task": "dmc_finger_turn_hard", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 0.0, 0.0, 77.3, 86.3, 167.0, 133.5, 443.7, 494.2, 328.9, 528.8, 502.4, 628.0, 858.4, 677.7, 853.6, 826.9, 922.3, 756.0, 844.5, 949.0, 811.4, 955.2, 886.3, 838.6, 873.8, 841.3, 665.1, 718.7, 736.6, 552.6, 872.0, 662.0, 909.4, 764.0, 709.4, 842.7, 964.0, 775.7, 976.8, 815.2, 929.8, 758.7, 940.7, 927.2, 821.7, 867.5, 914.4, 876.0, 909.6]}, {"task": "dmc_finger_turn_hard", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 88.9, 51.0, 176.1, 263.9, 44.7, 179.2, 612.5, 626.5, 552.9, 597.3, 764.1, 644.7, 823.0, 658.4, 863.5, 961.2, 864.7, 938.5, 851.0, 850.0, 765.8, 671.5, 917.1, 646.9, 922.4, 778.2, 873.6, 861.7, 826.8, 960.7, 869.9, 965.1, 879.9, 971.2, 873.8, 964.3, 816.8, 840.2, 936.0, 868.7, 673.0, 952.0, 869.0, 844.6, 844.5, 846.0, 600.5, 948.7, 927.8]}, {"task": "dmc_finger_turn_hard", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0], "ys": [0.0, 2.8, 17.9, 134.0, 294.3, 374.2, 243.3, 376.1, 453.7, 628.0, 797.6, 625.9, 758.8, 887.2, 950.1, 818.5, 572.2, 677.5, 697.3, 906.4, 897.5, 531.6, 762.3, 949.4, 742.1, 902.3, 866.0, 882.8, 932.3, 886.5, 807.8, 925.2, 746.7, 962.3, 817.3, 943.6]}, {"task": "dmc_pendulum_swingup", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 492.0, 793.4, 858.0, 825.1, 850.6, 696.1, 865.6, 809.6, 772.0, 827.9, 838.1, 774.4, 821.2, 763.1, 807.7, 845.9, 774.2, 869.2, 840.6, 879.1, 827.6, 753.7, 770.3, 800.9, 751.7, 747.5, 807.6, 844.0, 815.6, 705.0, 802.8, 843.4, 716.5, 788.2, 847.7, 771.3, 834.7, 799.8, 829.1, 770.7, 852.6, 748.6, 823.1, 817.9, 725.0, 798.3, 810.3, 751.9, 757.0]}, {"task": "dmc_pendulum_swingup", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 443.6, 794.6, 875.8, 838.9, 830.6, 858.3, 859.7, 849.5, 822.0, 859.0, 860.7, 811.5, 748.7, 848.6, 721.1, 858.8, 821.5, 872.0, 809.4, 861.1, 811.2, 806.0, 663.1, 727.5, 783.6, 831.6, 816.1, 829.4, 844.1, 874.0, 837.1, 813.3, 861.3, 774.9, 866.1, 741.4, 755.7, 837.1, 809.8, 817.4, 754.1, 835.8, 866.1, 818.2, 794.1, 817.9, 736.6, 832.7, 795.3]}, {"task": "dmc_pendulum_swingup", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 412.8, 795.0, 841.4, 868.3, 741.6, 811.6, 798.9, 800.4, 838.3, 816.8, 801.8, 769.7, 798.0, 843.1, 803.7, 785.7, 783.9, 834.6, 753.9, 675.8, 769.3, 674.8, 780.6, 823.7, 663.4, 789.9, 773.1, 827.7, 779.4, 778.2, 821.0, 849.9, 689.1, 816.4, 869.6, 840.2, 763.3, 820.9, 868.3, 787.7, 785.8, 642.6, 654.2, 796.0, 817.3, 872.2, 855.0, 812.3, 809.5]}, {"task": "dmc_pendulum_swingup", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [56.0, 82.5, 758.3, 864.4, 782.0, 701.6, 873.1, 823.3, 830.3, 830.6, 827.6, 799.2, 871.1, 821.8, 792.7, 825.2, 868.3, 857.0, 826.1, 872.2, 890.6, 777.6363636363636, 831.8888888888889, 867.6, 798.6, 796.9, 882.1818181818181, 799.6666666666666, 823.6, 721.2, 828.8, 796.1818181818181, 886.3, 805.0, 820.0, 793.5, 803.0, 826.5555555555555, 795.6, 828.2, 842.9090909090909, 821.6, 843.0, 858.6, 791.6, 848.6, 855.4, 768.4, 721.6, 810.7]}, {"task": "dmc_pendulum_swingup", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 395.5, 729.4, 788.1, 782.3, 821.7, 751.9, 784.9, 869.8, 826.6, 809.4, 791.3, 825.7, 769.1, 872.0, 840.6, 740.7, 846.8, 834.6, 821.0, 786.4, 831.2, 851.7, 796.9, 824.6, 803.3, 805.7, 877.0, 836.0, 799.0, 867.5, 791.6, 840.3, 843.3, 820.8, 776.5, 800.7, 788.4, 822.8, 849.6, 825.9, 790.3, 803.6, 797.1, 815.7, 776.0, 806.7, 822.2, 822.0, 787.6]}, {"task": "dmc_reacher_hard", "method": "dreamer", "seed": "0", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 7.5, 42.3, 1.7, 5.0, 100.0, 189.7, 135.9, 95.6, 48.9, 0.7, 339.4, 184.6, 385.3, 618.1, 397.2, 494.8, 521.9, 552.2, 772.1, 459.4, 370.9, 442.4, 656.5, 579.9, 670.1, 683.6, 436.3, 677.0, 767.0, 777.4, 581.4, 873.5, 797.8, 778.7, 769.6, 770.0, 739.9, 677.1, 870.1, 672.2, 923.1, 868.6, 887.5, 875.2, 876.1, 901.5, 880.1, 712.3, 963.8]}, {"task": "dmc_reacher_hard", "method": "dreamer", "seed": "1", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 0.4, 0.5, 1.3, 115.0, 184.0, 98.0, 95.8, 77.6, 143.7, 24.9, 484.7, 438.0, 477.4, 305.1, 294.2, 483.4, 773.3, 289.8, 287.6, 463.3, 753.9, 681.0, 689.3, 578.3, 382.3, 585.6, 578.5, 624.2, 841.5, 582.5, 386.8, 871.7, 777.4, 567.6, 773.8, 774.2, 857.3, 769.5, 780.7, 818.6, 583.7, 875.6, 772.4, 969.9, 977.0, 873.9, 821.8, 889.9, 967.8]}, {"task": "dmc_reacher_hard", "method": "dreamer", "seed": "4", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 2.9, 99.0, 85.6, 58.3, 81.9, 85.6, 4.0, 103.0, 219.5, 91.5, 474.7, 197.0, 575.8, 489.7, 386.3, 672.2, 671.3, 490.6, 583.7, 832.6, 783.8, 426.7, 324.6, 876.4, 666.8, 746.7, 486.1, 767.7, 782.0, 871.4, 923.4, 872.6, 775.9, 870.2, 673.6, 871.2, 676.7, 874.8, 777.6, 942.9, 965.7, 778.1, 860.9, 870.8, 961.9, 972.1, 866.7, 868.1, 965.1]}, {"task": "dmc_reacher_hard", "method": "dreamer", "seed": "3", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 0.5, 4.7, 100.4, 231.9, 1.4, 479.0, 104.8, 99.7, 134.2, 192.6, 201.9, 623.2, 353.6, 100.0, 387.2, 381.3, 171.8, 280.7, 679.8, 584.2, 488.6, 575.0, 679.2, 482.5, 679.7, 482.3, 657.4, 675.2, 580.1, 956.5, 723.4, 866.2, 777.6, 771.8, 675.8, 676.7, 878.3, 579.9, 673.4, 579.2, 681.6, 678.5, 966.3, 782.2, 972.4, 593.7, 969.3, 784.9, 777.3]}, {"task": "dmc_reacher_hard", "method": "dreamer", "seed": "2", "xs": [5000.0, 105000.0, 205000.0, 305000.0, 405000.0, 505000.0, 605000.0, 705000.0, 805000.0, 905000.0, 1005000.0, 1105000.0, 1205000.0, 1305000.0, 1405000.0, 1505000.0, 1605000.0, 1705000.0, 1805000.0, 1905000.0, 2005000.0, 2105000.0, 2205000.0, 2305000.0, 2405000.0, 2505000.0, 2605000.0, 2705000.0, 2805000.0, 2905000.0, 3005000.0, 3105000.0, 3205000.0, 3305000.0, 3405000.0, 3505000.0, 3605000.0, 3705000.0, 3805000.0, 3905000.0, 4005000.0, 4105000.0, 4205000.0, 4305000.0, 4405000.0, 4505000.0, 4605000.0, 4705000.0, 4805000.0, 4905000.0], "ys": [0.0, 1.3, 21.9, 42.3, 19.5, 108.9, 71.2, 0.3, 489.7, 40.7, 537.3, 316.6, 561.2, 452.1, 573.9, 577.0, 645.6, 483.8, 470.2, 573.5, 630.0, 479.0, 844.8, 494.4, 481.9, 773.5, 460.6, 518.9, 712.4, 639.3, 776.2, 777.1, 971.7, 868.9, 879.6, 870.9, 583.1, 755.2, 871.4, 776.9, 680.1, 675.9, 830.0, 778.0, 872.7, 866.1, 672.4, 739.8, 810.9, 871.1]}]


================================================
FILE: .github/ISSUE_TEMPLATE/issue.md
================================================
---
name: Issue
about: Ask a question, report a bug, or report any other issue.
title: ''
labels: ''
assignees: ''

---

<!--
Hi there, I'm happy to answer questions about the Dreamer agent, its implementation in this repository, and to look into bugs on a best-effort basis. This means that I sometimes respond quickly and sometimes it may take a few weeks when I'm busy.

There is a strict rule to open one issue per individual question. You might have multiple questions. In this case, open multiple issues for them. This lets others find existing questions more easily and lets me keep an overview.
-->


